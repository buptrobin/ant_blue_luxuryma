# æµå¼æ¨ç†è¾“å‡ºå®ç°æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¬¡å®ç°ä¸º LangGraph å·¥ä½œæµæ·»åŠ äº†**é€æ­¥æ¨ç†æµå¼è¾“å‡º**åŠŸèƒ½ï¼Œä½¿å‰ç«¯èƒ½å¤Ÿå®æ—¶çœ‹åˆ° LLM çš„æ€è€ƒè¿‡ç¨‹ã€‚

### æ ¸å¿ƒæ”¹è¿›

1. **Chain-of-Thought (CoT) æ¨ç†** - LLM åœ¨ç»™å‡ºç»“æœå‰å…ˆè¾“å‡ºæ¨ç†æ­¥éª¤
2. **å®æ—¶æµå¼ä¼ è¾“** - æ¨ç†è¿‡ç¨‹å’Œç»“æœé€šè¿‡ SSE æµå¼å‘é€åˆ°å‰ç«¯
3. **èŠ‚ç‚¹çº§æµå¼æ§åˆ¶** - å…³é”®èŠ‚ç‚¹æ”¯æŒæµå¼è¾“å‡ºï¼Œè®¡ç®—èŠ‚ç‚¹ä¿æŒå¿«é€Ÿå“åº”
4. **V2 æµå¼ Endpoint** - æ–°çš„ `/api/v1/analysis/v2/stream` endpoint

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. æµå¼èŠ‚ç‚¹ (Streaming Nodes)

æ–°æ–‡ä»¶ï¼š`backend/app/agent/streaming_nodes.py`

åŒ…å«4ä¸ªæ”¯æŒæµå¼æ¨ç†çš„èŠ‚ç‚¹ï¼š

| èŠ‚ç‚¹ | åŠŸèƒ½ | æ˜¯å¦æµå¼ | æ¨ç†å†…å®¹ |
|-----|------|---------|---------|
| `intent_recognition_node_stream` | æ„å›¾è¯†åˆ« | âœ… æµå¼ | åˆ†æä¸šåŠ¡ç›®æ ‡ã€äººç¾¤ç‰¹å¾ã€çº¦æŸæ¡ä»¶ |
| `feature_matching_node_stream` | ç‰¹å¾åŒ¹é… | âœ… æµå¼ | æ˜ å°„æ„å›¾åˆ°æ•°æ®åº“ç‰¹å¾ |
| `strategy_generation_node_stream` | ç­–ç•¥ç”Ÿæˆ | âœ… æµå¼ | ç»„åˆç‰¹å¾çš„ç­–ç•¥è§£é‡Š |
| `final_analysis_node_stream` | ç»“æœè¾“å‡º | âœ… æµå¼ | ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š |

**éæµå¼èŠ‚ç‚¹**ï¼ˆå¿«é€Ÿè®¡ç®—ï¼Œæ— éœ€æµå¼ï¼‰ï¼š
- `ask_clarification_node` - æ¾„æ¸…é—®é¢˜ç”Ÿæˆ
- `request_modification_node` - ä¿®æ­£å»ºè®®ç”Ÿæˆ
- `impact_prediction_node` - æ•ˆæœé¢„æµ‹ï¼ˆæ•°æ®è®¡ç®—ï¼‰

### 2. LLM æç¤ºè¯æ”¹è¿›

æ‰€æœ‰æµå¼èŠ‚ç‚¹çš„æç¤ºè¯éƒ½åŠ å…¥äº† **CoT æ¨ç†æŒ‡å¯¼**ï¼š

```python
prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¥é”€ä¸“å®¶...

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤åˆ†æï¼š

1. **ç†è§£éœ€æ±‚**ï¼šç”¨æˆ·æƒ³è¦è¾¾åˆ°ä»€ä¹ˆä¸šåŠ¡ç›®æ ‡ï¼Ÿ
2. **è¯†åˆ«äººç¾¤**ï¼šç”¨æˆ·æƒ³åœˆé€‰å“ªç±»äººç¾¤ï¼Ÿ
3. **æå–çº¦æŸ**ï¼šæœ‰ä»€ä¹ˆé™åˆ¶æ¡ä»¶ï¼Ÿ
4. **åˆ¤æ–­æ¸…æ™°åº¦**ï¼šç”¨æˆ·çš„æ„å›¾æ˜¯å¦è¶³å¤Ÿæ˜ç¡®ï¼Ÿ

è¯·å…ˆç”¨è‡ªç„¶è¯­è¨€é€æ­¥åˆ†æä½ çš„æ¨ç†è¿‡ç¨‹ï¼Œç„¶ååœ¨æœ€åè¿”å›JSONæ ¼å¼çš„ç»“æœï¼š

{{
  "reasoning": "è¿™é‡Œå†™ä½ çš„æ¨ç†è¿‡ç¨‹ï¼Œé€æ­¥åˆ†æ...",
  "business_goal": "...",
  ...
}}
"""
```

### 3. æµå¼å·¥ä½œæµç¼–æ’

æ–°å‡½æ•°ï¼š`backend/app/agent/graph.py::run_agent_stream_v2()`

æ‰‹åŠ¨ç¼–æ’èŠ‚ç‚¹æ‰§è¡Œé¡ºåºï¼Œæ”¯æŒæ¡ä»¶è·¯ç”±å’Œæµå¼è¾“å‡ºï¼š

```python
async def run_agent_stream_v2(user_input, conversation_history):
    # Step 1: Intent Recognition (æµå¼)
    async for event in intent_recognition_node_stream(state):
        yield event
        if event["type"] == "node_complete":
            state.update(event["data"])

    # æ¡ä»¶è·¯ç”±
    if state.get("intent_status") == "ambiguous":
        # è¿”å›æ¾„æ¸…é—®é¢˜
        clarification_result = await ask_clarification_node(state)
        yield node_complete_event
        return  # æå‰ç»“æŸ

    # Step 2: Feature Matching (æµå¼)
    async for event in feature_matching_node_stream(state):
        yield event
        ...

    # Step 3-5: ç»§ç»­æ‰§è¡Œ...
```

### 4. SSE æµå¼ Endpoint

æ–° endpointï¼š`GET /api/v1/analysis/v2/stream`

**è¯·æ±‚å‚æ•°ï¼š**
- `prompt` (query string): ç”¨æˆ·è¾“å…¥
- `session_id` (optional): Session ID for multi-turn

**SSE äº‹ä»¶ç±»å‹ï¼š**

```typescript
// 1. èŠ‚ç‚¹å¼€å§‹
{
  "type": "node_start",
  "node": "intent_recognition",
  "title": "æ„å›¾è¯†åˆ«"
}

// 2. æ¨ç†æ­¥éª¤ï¼ˆé€å­—æµå¼ï¼‰
{
  "type": "reasoning",
  "node": "intent_recognition",
  "data": "æˆ‘é¦–å…ˆåˆ†æç”¨æˆ·çš„ä¸šåŠ¡ç›®æ ‡..."
}

// 3. èŠ‚ç‚¹å®Œæˆ
{
  "type": "node_complete",
  "node": "intent_recognition",
  "data": {
    "user_intent": {...},
    "intent_status": "clear",
    "reasoning": "å®Œæ•´æ¨ç†è¿‡ç¨‹..."
  }
}

// 4. å·¥ä½œæµå®Œæˆ
{
  "type": "workflow_complete",
  "status": "success",
  "session_id": "abc123",
  "data": {
    "response": "æœ€ç»ˆæŠ¥å‘Š...",
    "user_intent": {...},
    "matched_features": [...],
    "prediction_result": {...}
  }
}

// 5. é”™è¯¯
{
  "type": "error",
  "data": "é”™è¯¯ä¿¡æ¯"
}
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å¯åŠ¨åç«¯æœåŠ¡å™¨

```bash
cd backend
uvicorn app.main:app --reload
```

### 2. æµ‹è¯•æµå¼ Endpoint

**æ–¹æ³•1ï¼šä½¿ç”¨æµ‹è¯•è„šæœ¬**

```bash
cd backend
python test_streaming_v2.py
```

**æ–¹æ³•2ï¼šä½¿ç”¨ curl**

```bash
curl -N "http://localhost:8000/api/v1/analysis/v2/stream?prompt=æˆ‘è¦ä¸ºæ˜¥å­£æ–°æ¬¾æ‰‹è¢‹ä¸Šå¸‚åšä¸€æ¬¡æ¨å¹¿ï¼Œç›®æ ‡æ˜¯æå‡è½¬åŒ–ç‡ã€‚åœˆé€‰VVIPå’ŒVIPå®¢æˆ·ã€‚"
```

**æ–¹æ³•3ï¼šä½¿ç”¨ httpx (Python)**

```python
import httpx
import json

async with httpx.AsyncClient() as client:
    async with client.stream(
        "GET",
        "http://localhost:8000/api/v1/analysis/v2/stream",
        params={"prompt": "å¸®æˆ‘åœˆé€‰VIPå®¢æˆ·"}
    ) as response:
        async for line in response.aiter_lines():
            if line.startswith("data: "):
                event = json.loads(line[6:])
                print(event)
```

### 3. å‰ç«¯é›†æˆç¤ºä¾‹

**ä½¿ç”¨ EventSource (æµè§ˆå™¨åŸç”Ÿ API)**

```javascript
const prompt = "æˆ‘è¦ä¸ºæ˜¥å­£æ–°æ¬¾æ‰‹è¢‹ä¸Šå¸‚åšä¸€æ¬¡æ¨å¹¿";
const url = `/api/v1/analysis/v2/stream?prompt=${encodeURIComponent(prompt)}`;

const eventSource = new EventSource(url);

// æ‰€æœ‰äº‹ä»¶éƒ½é€šè¿‡ 'message' ç›‘å¬
eventSource.addEventListener('message', (e) => {
  const event = JSON.parse(e.data);

  switch (event.type) {
    case 'node_start':
      console.log(`[èŠ‚ç‚¹å¼€å§‹] ${event.title}`);
      break;

    case 'reasoning':
      // å®æ—¶æ˜¾ç¤ºLLMæ¨ç†è¿‡ç¨‹
      appendReasoningText(event.node, event.data);
      break;

    case 'node_complete':
      console.log(`[èŠ‚ç‚¹å®Œæˆ] ${event.node}`);
      updateNodeStatus(event.node, 'completed', event.data);
      break;

    case 'workflow_complete':
      console.log(`[å·¥ä½œæµå®Œæˆ] ${event.status}`);
      displayFinalResult(event.data);
      eventSource.close();
      break;

    case 'error':
      console.error(`[é”™è¯¯] ${event.data}`);
      eventSource.close();
      break;
  }
});

eventSource.onerror = (error) => {
  console.error('SSE Error:', error);
  eventSource.close();
};
```

**ä½¿ç”¨ fetch (æ›´çµæ´»çš„æ§åˆ¶)**

```javascript
async function streamAnalysis(prompt) {
  const response = await fetch(
    `/api/v1/analysis/v2/stream?prompt=${encodeURIComponent(prompt)}`
  );

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value);
    const lines = chunk.split('\n');

    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const event = JSON.parse(line.slice(6));
        handleEvent(event);
      }
    }
  }
}
```

---

## ğŸ“Š å·¥ä½œæµç¤ºä¾‹

### åœºæ™¯1ï¼šæ˜ç¡®æ„å›¾ - å®Œæ•´æµç¨‹

**ç”¨æˆ·è¾“å…¥ï¼š**
> æˆ‘è¦ä¸ºæ˜¥å­£æ–°æ¬¾æ‰‹è¢‹ä¸Šå¸‚åšä¸€æ¬¡æ¨å¹¿ï¼Œç›®æ ‡æ˜¯æå‡è½¬åŒ–ç‡ã€‚åœˆé€‰VVIPå’ŒVIPå®¢æˆ·ï¼Œå¹´é¾„åœ¨25-44å²ã€‚

**æµå¼è¾“å‡ºè¿‡ç¨‹ï¼š**

```
ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ æ„å›¾è¯†åˆ«
--------------------------------------------------------------------------------
[æ¨ç†] æˆ‘é¦–å…ˆåˆ†æç”¨æˆ·çš„ä¸šåŠ¡ç›®æ ‡ã€‚ç”¨æˆ·æ˜ç¡®æåˆ°"æ˜¥å­£æ–°æ¬¾æ‰‹è¢‹ä¸Šå¸‚"å’Œ"æå‡è½¬åŒ–ç‡"ï¼Œ
è¿™è¡¨æ˜ç›®æ ‡æ˜¯é’ˆå¯¹ç‰¹å®šäº§å“çš„é”€å”®è½¬åŒ–ä¼˜åŒ–...

æ¥ä¸‹æ¥è¯†åˆ«ç›®æ ‡äººç¾¤ã€‚ç”¨æˆ·æŒ‡å®šäº†"VVIPå’ŒVIPå®¢æˆ·"ï¼Œè¿™æ˜¯æ˜ç¡®çš„ä¼šå‘˜ç­‰çº§ç­›é€‰...

å¹´é¾„èŒƒå›´"25-44å²"ä¹Ÿå¾ˆæ¸…æ™°ï¼Œè¿™æ˜¯å¥¢ä¾ˆå“æ‰‹è¢‹çš„æ ¸å¿ƒæ¶ˆè´¹ç¾¤ä½“...

ç»¼åˆåˆ¤æ–­ï¼šç”¨æˆ·æ„å›¾éå¸¸æ˜ç¡®ï¼ŒåŒ…å«ä¸šåŠ¡ç›®æ ‡ã€äººç¾¤ç‰¹å¾å’Œçº¦æŸæ¡ä»¶ã€‚is_clearåº”ä¸ºtrueã€‚

âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ intent_recognition
  - æ„å›¾çŠ¶æ€: clear
  - ä¸šåŠ¡ç›®æ ‡: æå‡æ˜¥å­£æ–°æ¬¾æ‰‹è¢‹è½¬åŒ–ç‡
--------------------------------------------------------------------------------

ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ ç‰¹å¾åŒ¹é…
--------------------------------------------------------------------------------
[æ¨ç†] åˆ†æéœ€æ±‚ï¼šç”¨æˆ·éœ€è¦ç­›é€‰VVIP/VIPå®¢æˆ·ã€å¹´é¾„25-44å²...

åŒ¹é…ç‰¹å¾ï¼š
1. ä¼šå‘˜ç­‰çº§ -> tierå­—æ®µï¼Œä½¿ç”¨inæ“ä½œç¬¦ï¼Œå€¼ä¸º["VVIP", "VIP"]
2. å¹´é¾„æ®µ -> age_groupå­—æ®µï¼Œä½¿ç”¨inæ“ä½œç¬¦ï¼Œå€¼ä¸º["25-34", "35-44"]
3. æ‰‹è¢‹å…´è¶£ -> handbag_browse_countå­—æ®µï¼Œä½¿ç”¨>æ“ä½œç¬¦...

éªŒè¯å¯è¡Œæ€§ï¼šæ‰€æœ‰æ¡ä»¶éƒ½èƒ½ç”¨ç°æœ‰ç‰¹å¾æ»¡è¶³ï¼Œis_success=trueã€‚

âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ feature_matching
  - åŒ¹é…ç‰¹å¾æ•°: 4
    Â· ä¼šå‘˜ç­‰çº§ä¸ºVVIPæˆ–VIP
    Â· å¹´é¾„æ®µåœ¨25-44å²
    Â· æµè§ˆæ‰‹è¢‹å“ç±»è¶…è¿‡5æ¬¡
    Â· è¿‘12ä¸ªæœˆæ¶ˆè´¹é¢å¤§äº50000å…ƒ
--------------------------------------------------------------------------------

ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ ç­–ç•¥ç”Ÿæˆ
--------------------------------------------------------------------------------
[æ¨ç†] æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨ä»¥ä¸‹åœˆé€‰ç­–ç•¥ï¼š

**ç›®æ ‡äººç¾¤å®šä½**ï¼šé”å®šVVIPå’ŒVIPå®¢æˆ·ï¼Œå¹´é¾„åœ¨25-44å²ä¹‹é—´ï¼Œè¿™ä¸€ç¾¤ä½“æ˜¯å¥¢ä¾ˆå“æ‰‹è¢‹çš„
æ ¸å¿ƒæ¶ˆè´¹è€…ï¼Œè´­ä¹°åŠ›å¼ºä¸”å“ç‰Œå¿ è¯šåº¦é«˜...

**è¡Œä¸ºç­›é€‰**ï¼šä¼˜å…ˆé€‰æ‹©è¿‘æœŸæµè§ˆæ‰‹è¢‹å“ç±»è¶…è¿‡5æ¬¡çš„ç”¨æˆ·ï¼Œè¡¨æ˜å¯¹æ–°å“æœ‰æ˜ç¡®å…´è¶£...

**é¢„æœŸæ•ˆæœ**ï¼šè¿™ä¸€ç­–ç•¥èƒ½å¤Ÿç²¾å‡†è§¦è¾¾é«˜ä»·å€¼ã€é«˜æ„å‘çš„æ½œåœ¨å®¢æˆ·ï¼Œé¢„è®¡è½¬åŒ–ç‡å¯æå‡30-50%...

âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ strategy_generation
  - ç­–ç•¥è¯´æ˜: æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨ä»¥ä¸‹åœˆé€‰ç­–ç•¥...
--------------------------------------------------------------------------------

ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ æ•ˆæœé¢„æµ‹
âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ impact_prediction
  - åœˆé€‰äººæ•°: 28
  - é¢„ä¼°è½¬åŒ–ç‡: 8.5%
  - é¢„ä¼°æ”¶å…¥: Â¥336,000
--------------------------------------------------------------------------------

ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ ç»“æœè¾“å‡º
--------------------------------------------------------------------------------
[æ¨ç†] # åœˆäººåˆ†ææŠ¥å‘Š

## åœˆé€‰ç»“æœæ¦‚è§ˆ
- **åœˆé€‰äººæ•°**: 28äºº
- **ä¼šå‘˜åˆ†å¸ƒ**: VVIP 12äººï¼ŒVIP 16äºº
- **äººç¾¤è´¨é‡åˆ†**: 87.5/100

## æ ¸å¿ƒæŒ‡æ ‡é¢„æµ‹
...

âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ final_analysis
--------------------------------------------------------------------------------

ğŸ‰ ã€å·¥ä½œæµå®Œæˆã€‘ çŠ¶æ€: success
  æœ€ç»ˆé¢„æµ‹ç»“æœ:
  - åœˆé€‰äººæ•°: 28
  - é¢„ä¼°è½¬åŒ–ç‡: 8.50%
  - é¢„ä¼°æ”¶å…¥: Â¥336,000
  - ROI: 5.0å€
```

### åœºæ™¯2ï¼šæ¨¡ç³Šæ„å›¾ - æ—©æœŸé€€å‡º

**ç”¨æˆ·è¾“å…¥ï¼š**
> å¸®æˆ‘åœˆé€‰ä¸€äº›ç”¨æˆ·

**æµå¼è¾“å‡ºè¿‡ç¨‹ï¼š**

```
ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ æ„å›¾è¯†åˆ«
--------------------------------------------------------------------------------
[æ¨ç†] æˆ‘é¦–å…ˆåˆ†æç”¨æˆ·çš„ä¸šåŠ¡ç›®æ ‡ã€‚ç”¨æˆ·åªæåˆ°"åœˆé€‰ä¸€äº›ç”¨æˆ·"ï¼Œæ²¡æœ‰è¯´æ˜å…·ä½“çš„è¥é”€ç›®æ ‡...

æ¥ä¸‹æ¥è¯†åˆ«ç›®æ ‡äººç¾¤ã€‚ç”¨æˆ·æ²¡æœ‰æä¾›ä»»ä½•äººç¾¤ç‰¹å¾ï¼Œæ¯”å¦‚ä¼šå‘˜ç­‰çº§ã€å¹´é¾„ã€æ¶ˆè´¹åŠ›ç­‰...

ç»¼åˆåˆ¤æ–­ï¼šç”¨æˆ·æ„å›¾éå¸¸æ¨¡ç³Šï¼Œç¼ºå°‘å…³é”®ä¿¡æ¯ã€‚is_clearåº”ä¸ºfalseã€‚

âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ intent_recognition
  - æ„å›¾çŠ¶æ€: ambiguous
--------------------------------------------------------------------------------

ğŸš€ ã€èŠ‚ç‚¹å¼€å§‹ã€‘ æ¾„æ¸…é—®é¢˜
âœ… ã€èŠ‚ç‚¹å®Œæˆã€‘ ask_clarification

æ¾„æ¸…é—®é¢˜:
æˆ‘ç†è§£æ‚¨æƒ³è¿›è¡Œäººç¾¤åœˆé€‰ã€‚ä¸ºäº†æ›´ç²¾å‡†åœ°å¸®æ‚¨ï¼Œèƒ½å¦å‘Šè¯‰æˆ‘ï¼š
1. æ‚¨çš„æ ¸å¿ƒç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆæå‡è½¬åŒ–ç‡ã€å¢åŠ è¥æ”¶ã€ä¿ƒè¿›åˆ°åº—ï¼Ÿï¼‰
2. æ‚¨å¸Œæœ›åœˆé€‰å“ªç±»å®¢æˆ·ï¼Ÿï¼ˆVIPå®¢æˆ·ã€å¹´è½»å®¢æˆ·ã€é«˜æ¶ˆè´¹å®¢æˆ·ï¼Ÿï¼‰
3. æœ‰ä»€ä¹ˆçº¦æŸæ¡ä»¶å—ï¼Ÿï¼ˆäººç¾¤è§„æ¨¡ã€é¢„ç®—ã€æ’é™¤æ¡ä»¶ï¼Ÿï¼‰
--------------------------------------------------------------------------------

ğŸ‰ ã€å·¥ä½œæµå®Œæˆã€‘ çŠ¶æ€: clarification_needed

æœ€ç»ˆå“åº”:
æˆ‘ç†è§£æ‚¨æƒ³è¿›è¡Œäººç¾¤åœˆé€‰ã€‚ä¸ºäº†æ›´ç²¾å‡†åœ°å¸®æ‚¨ï¼Œèƒ½å¦å‘Šè¯‰æˆ‘ï¼š...
```

---

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### 1. æµå¼æ¨ç†å®ç°åŸç†

```python
async def stream_llm_with_reasoning(prompt: str, max_tokens: int):
    """æ ¸å¿ƒæµå¼æ¨ç†å‡½æ•°"""
    llm = get_llm_manager()
    full_response = ""

    # æµå¼è·å–LLMè¾“å‡º
    async for chunk in llm.model.stream(prompt, max_tokens=max_tokens):
        full_response += chunk
        # ç«‹å³å‘é€æ¨ç†ç‰‡æ®µ
        yield {"type": "reasoning", "data": chunk}

    # è§£ææœ€ç»ˆJSONç»“æœ
    json_match = re.search(r'\{.*\}', full_response, re.DOTALL)
    if json_match:
        result = json.loads(json_match.group())
        yield {"type": "result", "data": result}
```

**å…³é”®ç‚¹ï¼š**
- ä½¿ç”¨ `llm.model.stream()` è·å– token-level æµå¼è¾“å‡º
- æ¯ä¸ª chunk ç«‹å³é€šè¿‡ `yield` å‘é€åˆ°å‰ç«¯
- æœ€ç»ˆè§£æå®Œæ•´å“åº”æå–JSONç»“æœ

### 2. èŠ‚ç‚¹æµå¼åŒ…è£…

```python
async def intent_recognition_node_stream(state):
    """æµå¼èŠ‚ç‚¹æ¨¡æ¿"""
    # 1. å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
    yield {"type": "node_start", "node": "intent_recognition", "title": "æ„å›¾è¯†åˆ«"}

    # 2. æ„å»ºå¸¦CoTçš„prompt
    prompt = f"""..."""

    # 3. æµå¼è°ƒç”¨LLM
    async for event in stream_llm_with_reasoning(prompt):
        if event["type"] == "reasoning":
            # è½¬å‘æ¨ç†æ­¥éª¤
            yield {"type": "reasoning", "node": "intent_recognition", "data": event["data"]}

        elif event["type"] == "result":
            # è§£æç»“æœå¹¶å‘é€èŠ‚ç‚¹å®Œæˆäº‹ä»¶
            result = event["data"]
            yield {
                "type": "node_complete",
                "node": "intent_recognition",
                "data": {...parsed result...}
            }
```

### 3. SSE å“åº”æ ¼å¼

æ‰€æœ‰äº‹ä»¶éƒ½ä½¿ç”¨æ ‡å‡† SSE æ ¼å¼ï¼š

```
data: {"type": "node_start", "node": "intent_recognition", "title": "æ„å›¾è¯†åˆ«"}\n\n
data: {"type": "reasoning", "node": "intent_recognition", "data": "æˆ‘é¦–å…ˆ..."}\n\n
data: {"type": "node_complete", "node": "intent_recognition", "data": {...}}\n\n
```

**æ³¨æ„ï¼š**
- æ¯ä¸ªäº‹ä»¶ä»¥ `data: ` å¼€å¤´
- JSON æ ¼å¼çš„äº‹ä»¶æ•°æ®
- äº‹ä»¶ä»¥åŒæ¢è¡Œç¬¦ `\n\n` ç»“å°¾

---

## ğŸ“ é…ç½®è¯´æ˜

### LLM Token é™åˆ¶

ä¸ºäº†æ§åˆ¶æ¨ç†è¿‡ç¨‹çš„é•¿åº¦ï¼Œæ‰€æœ‰æµå¼èŠ‚ç‚¹éƒ½è®¾ç½®äº† `max_tokens` é™åˆ¶ï¼š

```python
# backend/app/agent/streaming_nodes.py
async for event in stream_llm_with_reasoning(prompt, max_tokens=600):
    ...
```

**æ¨èå€¼ï¼š**
- `intent_recognition`: 600 tokens
- `feature_matching`: 700 tokens
- `strategy_generation`: 600 tokens
- `final_analysis`: 800 tokens

### API è¶…æ—¶è®¾ç½®

æµå¼è¯·æ±‚éœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼š

```python
# Client-side
async with httpx.AsyncClient(timeout=120.0) as client:
    ...
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. LLM ä¾èµ–

- æ‰€æœ‰æµå¼èŠ‚ç‚¹éƒ½ä¾èµ– LLM çš„æµå¼è¾“å‡ºèƒ½åŠ›
- ç¡®ä¿ `app.models.llm.ArkChat.stream()` æ­£å¸¸å·¥ä½œ
- å¦‚æœ LLM ä¸å¯ç”¨ï¼Œä¼šfallbackåˆ°mockå“åº”

### 2. æ€§èƒ½è€ƒè™‘

- æµå¼è¾“å‡ºå¢åŠ äº† API å“åº”æ—¶é—´ï¼ˆå› ä¸ºéœ€è¦ç­‰å¾… LLM é€å­—ç”Ÿæˆï¼‰
- å»ºè®®åªåœ¨éœ€è¦æŸ¥çœ‹æ¨ç†è¿‡ç¨‹æ—¶ä½¿ç”¨æµå¼ endpoint
- å¦‚æœåªéœ€è¦æœ€ç»ˆç»“æœï¼Œä½¿ç”¨éæµå¼ `/analysis/v2` endpoint

### 3. é”™è¯¯å¤„ç†

- æ¯ä¸ªæµå¼èŠ‚ç‚¹éƒ½æœ‰ try-except åŒ…è£…
- é”™è¯¯ä¼šé€šè¿‡ SSE äº‹ä»¶å‘é€ï¼š`{"type": "error", "data": "..."}`
- å‰ç«¯åº”æ­£ç¡®å¤„ç†é”™è¯¯äº‹ä»¶å¹¶å…³é—­è¿æ¥

### 4. Session ç®¡ç†

- V2 æµå¼ endpoint æ”¯æŒå¤šè½®å¯¹è¯
- é€šè¿‡ `session_id` å‚æ•°ä¼ é€’ session
- å¯¹è¯å†å²ä¼šå½±å“LLMçš„æ¨ç†è¿‡ç¨‹

---

## ğŸ§ª æµ‹è¯•æ¸…å•

- [x] æ˜ç¡®æ„å›¾ - å®Œæ•´æµç¨‹
- [x] æ¨¡ç³Šæ„å›¾ - æ¾„æ¸…é—®é¢˜
- [x] ç‰¹å¾åŒ¹é…å¤±è´¥ - ä¿®æ­£å»ºè®®
- [x] æ¨ç†å†…å®¹å®æ—¶æµå¼ä¼ è¾“
- [x] èŠ‚ç‚¹çŠ¶æ€æ­£ç¡®æ›´æ–°
- [x] å·¥ä½œæµå®Œæˆäº‹ä»¶
- [x] é”™è¯¯å¤„ç†å’Œé”™è¯¯äº‹ä»¶
- [ ] å‰ç«¯é›†æˆæµ‹è¯•
- [ ] å¤šè½®å¯¹è¯æµå¼å¤„ç†
- [ ] é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

### æ–°å¢æ–‡ä»¶
- `backend/app/agent/streaming_nodes.py` - æµå¼èŠ‚ç‚¹å®ç°
- `backend/test_streaming_v2.py` - æµå¼endpointæµ‹è¯•è„šæœ¬
- `STREAMING_GUIDE.md` - æœ¬æ–‡æ¡£

### ä¿®æ”¹æ–‡ä»¶
- `backend/app/agent/graph.py` - æ·»åŠ  `run_agent_stream_v2()` å‡½æ•°
- `backend/app/api/routes.py` - æ·»åŠ  `/analysis/v2/stream` endpoint

### ç›¸å…³æ–‡ä»¶
- `backend/app/models/llm.py` - LLM æµå¼è°ƒç”¨å®ç°
- `backend/app/agent/nodes.py` - éæµå¼èŠ‚ç‚¹å®ç°
- `backend/app/agent/state.py` - State schemaå®šä¹‰

---

## ğŸ”œ åç»­ä¼˜åŒ–å»ºè®®

1. **æµå¼èŠ‚ç‚¹æ€§èƒ½ä¼˜åŒ–**
   - å‡å°‘ LLM prompt é•¿åº¦
   - ä¼˜åŒ– token ä½¿ç”¨æ•ˆç‡
   - ç¼“å­˜é‡å¤çš„ç‰¹å¾å…ƒæ•°æ®

2. **å‰ç«¯ç”¨æˆ·ä½“éªŒ**
   - æ‰“å­—æœºæ•ˆæœæ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
   - å¯æŠ˜å çš„æ¨ç†è¿‡ç¨‹é¢æ¿
   - è¿›åº¦æ¡æ˜¾ç¤ºèŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€

3. **æ¨ç†è´¨é‡æå‡**
   - Few-shot examples in prompts
   - æ›´ç²¾ç»†çš„ CoT æ­¥éª¤åˆ’åˆ†
   - æ¨ç†è¿‡ç¨‹çš„è´¨é‡è¯„ä¼°

4. **ç›‘æ§å’Œè°ƒè¯•**
   - è®°å½•æ¨ç†è¿‡ç¨‹åˆ°æ—¥å¿—
   - æ¨ç†è´¨é‡åˆ†æå·¥å…·
   - A/Bæµ‹è¯•ä¸åŒpromptç­–ç•¥

---

**å®ç°å®Œæˆæ—¶é—´:** 2026-01-17
**ç‰ˆæœ¬:** V2.1 - Streaming with Chain-of-Thought
