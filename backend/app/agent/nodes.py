"""LangGraph nodes for the marketing agent - Refactored for multi-turn dialogue."""
import logging
import json
import re
from typing import Any

from app.agent.state import AgentState, UserIntent, MatchedFeature, PredictionResult
from app.models.llm import get_llm_manager
from app.models.segmentation import SegmentationProposal, TargetTrait, FeatureRule
from app.data.feature_metadata import FEATURE_METADATA, search_features_by_keywords
from app.data.mock_users import MOCK_USERS_WITH_FEATURES
from langgraph.types import Send, interrupt

logger = logging.getLogger(__name__)


# =====================================================
# Node A: intent_recognition (æ„å›¾è¯†åˆ«)
# =====================================================
async def intent_recognition_node(state: AgentState) -> dict[str, Any]:
    """
    Node A: æ„å›¾è¯†åˆ«

    åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«ä¸šåŠ¡ç›®æ ‡ã€ç›®æ ‡äººç¾¤å’Œçº¦æŸæ¡ä»¶ã€‚
    åˆ¤æ–­æ„å›¾æ˜¯å¦æ˜ç¡®ï¼Œå¦‚æœä¸æ˜ç¡®åˆ™æ ‡è®°ä¸º "ambiguous"ã€‚
    æ”¯æŒå¤šè½®å¯¹è¯ï¼Œä¼šè€ƒè™‘å¯¹è¯å†å²ã€‚
    """
    logger.info("Executing intent_recognition_node")

    user_input = state.get("user_input", "")
    messages = state.get("messages", [])
    conversation_context = state.get("conversation_context", "")
    previous_intent = state.get("previous_intent")  # ğŸ”¥ è·å–ä¸Šä¸€è½®çš„ç»“æ„åŒ–æ„å›¾

    llm = get_llm_manager()

    # ğŸ”¥ æ„å»ºæç¤ºè¯ - å¦‚æœæœ‰ä¸Šä¸€è½®æ„å›¾ï¼Œä½¿ç”¨å®ƒä½œä¸ºåŸºçº¿
    context_section = ""
    if previous_intent:
        # æœ‰å¯¹è¯å†å² - å¤šè½®å¯¹è¯æ¨¡å¼ï¼Œä½¿ç”¨ä¸Šä¸€è½®æ„å›¾ä½œä¸ºåŸºçº¿
        logger.info(f"Multi-turn mode: Using previous intent as baseline")
        logger.info(f"Previous intent: {previous_intent}")

        # å°†ä¸Šä¸€è½®æ„å›¾è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ï¼Œä½œä¸ºèåˆçš„åŸºçº¿
        previous_intent_json = json.dumps(previous_intent, ensure_ascii=False, indent=2)

        context_section = f"""
{conversation_context}

**å¤šè½®å¯¹è¯æ¨¡å¼ - é‡è¦**ï¼š
è¿™æ˜¯ä¸€ä¸ªå¤šè½®å¯¹è¯ã€‚ä¸Šä¸€è½®æˆ‘ä»¬å·²ç»è¯†åˆ«å‡ºçš„æ„å›¾æ˜¯ï¼š

```json
{previous_intent_json}
```

ç°åœ¨ç”¨æˆ·æä¾›äº†æ–°çš„è¾“å…¥ï¼š"{user_input}"

**ä½ çš„ä»»åŠ¡**ï¼š
1. **ä»¥ä¸Šä¸€è½®æ„å›¾ä¸ºåŸºçº¿**ï¼šå¦‚æœæ–°è¾“å…¥æ²¡æœ‰æåˆ°æŸä¸ªå­—æ®µï¼ˆå¦‚business_goalã€kpiï¼‰ï¼Œä¿ç•™ä¸Šä¸€è½®çš„å€¼
2. **ç´¯ç§¯çº¦æŸæ¡ä»¶**ï¼šå°†æ–°çš„çº¦æŸæ¡ä»¶è¿½åŠ åˆ°constraintsåˆ—è¡¨ä¸­ï¼ˆé™¤éç”¨æˆ·æ˜ç¡®è¯´"å»æ‰"æŸæ¡ä»¶ï¼‰
3. **æ›´æ–°æåˆ°çš„å­—æ®µ**ï¼šå¦‚æœæ–°è¾“å…¥æåˆ°äº†æŸä¸ªç»´åº¦ï¼ˆå¦‚æ¶ˆè´¹åå¥½ã€æ€§åˆ«ï¼‰ï¼Œæ›´æ–°target_audienceä¸­çš„å¯¹åº”å­—æ®µ
4. **è¦†ç›–å†²çªä¿¡æ¯**ï¼šå¦‚æœæ–°è¾“å…¥ä¸å†å²å†²çªï¼ˆå¦‚ä¹‹å‰è¯´"VIP"ï¼Œç°åœ¨è¯´"VVIP"ï¼‰ï¼Œä»¥æ–°è¾“å…¥ä¸ºå‡†

**å…³é”®**ï¼šä¸è¦ä»å¤´æ„å»ºæ„å›¾ï¼ä»ä¸Šé¢çš„previous_intentå¼€å§‹ï¼Œæ ¹æ®æ–°è¾“å…¥è¿›è¡Œå¢é‡æ›´æ–°ã€‚

"""
    else:
        # é¦–æ¬¡å¯¹è¯
        context_section = f"""
ç”¨æˆ·è¾“å…¥ï¼š{user_input}

"""

    prompt = f"""{context_section}ä½ æ˜¯ä¸€ä¸ªè¥é”€ä¸“å®¶ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·çš„åœˆäººéœ€æ±‚ã€‚

{"**é‡è¦æé†’**ï¼šè¿™æ˜¯å¤šè½®å¯¹è¯ï¼Œä½ å¿…é¡»åœ¨ä¸Šä¸€è½®æ„å›¾çš„åŸºç¡€ä¸Šè¿›è¡Œå¢é‡æ›´æ–°ï¼Œè€Œä¸æ˜¯ä»é›¶å¼€å§‹ã€‚" if previous_intent else ""}

è¯·åˆ†æ{"ç”¨æˆ·çš„æ–°è¾“å…¥ï¼Œå¹¶æ›´æ–°æ„å›¾" if previous_intent else "ç”¨æˆ·çš„æ„å›¾"}ï¼Œå¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

- business_goal: ä¸šåŠ¡ç›®æ ‡ï¼ˆå¦‚ "æå‡è½¬åŒ–ç‡", "æ‰©å¤§å®¢æˆ·ç¾¤", "ä¿ƒè¿›å¤è´­"ç­‰ï¼‰{"- å¦‚æœæ–°è¾“å…¥æœªæåŠï¼Œä¿ç•™ä¸Šä¸€è½®çš„å€¼" if previous_intent else ""}
- target_audience: ç›®æ ‡äººç¾¤æè¿°ï¼ˆåŒ…å«ä¼šå‘˜ç­‰çº§ã€å¹´é¾„ã€æ€§åˆ«ã€æ¶ˆè´¹åŠ›ç­‰ç»´åº¦ï¼‰{"- åªæ›´æ–°æ–°è¾“å…¥æåˆ°çš„å­—æ®µï¼Œå…¶ä»–å­—æ®µä¿ç•™ä¸Šä¸€è½®çš„å€¼" if previous_intent else ""}
- constraints: **æ‰€æœ‰çš„**çº¦æŸæ¡ä»¶åˆ—è¡¨ï¼ˆå¦‚ "æ’é™¤è¿‘æœŸå·²è´­ä¹°ç”¨æˆ·", "åªè¦å¥³æ€§å®¢æˆ·"ç­‰ï¼‰{"- åœ¨ä¸Šä¸€è½®çš„åŸºç¡€ä¸Šè¿½åŠ æ–°çº¦æŸ" if previous_intent else ""}
- kpi: æ ¸å¿ƒKPIï¼ˆconversion_rate/revenue/visit_rate/engagementï¼‰{"- å¦‚æœæ–°è¾“å…¥æœªæåŠï¼Œä¿ç•™ä¸Šä¸€è½®çš„å€¼" if previous_intent else ""}
- size_preference: äººç¾¤è§„æ¨¡åå¥½ {{"min": æœ€å°äººæ•°, "max": æœ€å¤§äººæ•°}}{"- å¦‚æœæ–°è¾“å…¥æœªæåŠï¼Œä¿ç•™ä¸Šä¸€è½®çš„å€¼" if previous_intent else ""}
- is_clear: æ„å›¾æ˜¯å¦æ˜ç¡®ï¼ˆtrue/falseï¼‰ã€‚å¦‚æœç”¨æˆ·æè¿°æ¨¡ç³Šã€ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼Œåˆ™ä¸ºfalse
- summary: ç”¨1-2å¥è¯æ€»ç»“ä½ å¯¹ç”¨æˆ·**å®Œæ•´éœ€æ±‚**çš„ç†è§£ï¼ˆèåˆæ‰€æœ‰å†å²ä¿¡æ¯åçš„ç†è§£ï¼‰

{"**å†æ¬¡å¼ºè°ƒ**ï¼šä½ å¿…é¡»ä»¥ä¸Šé¢æä¾›çš„previous_intentä¸ºèµ·ç‚¹ï¼Œæ ¹æ®æ–°è¾“å…¥è¿›è¡Œå¢é‡ä¿®æ”¹ã€‚ä¸è¦ä¸¢å¤±ä»»ä½•å†å²ä¿¡æ¯ï¼" if previous_intent else ""}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚

ç¤ºä¾‹ï¼š
{{
  "business_goal": "æå‡æ˜¥å­£æ–°å“è½¬åŒ–ç‡",
  "target_audience": {{
    "tier": ["VVIP"],
    "age_group": "25-44",
    "gender": "female",
    "has_recent_purchase": false
  }},
  "constraints": ["æ’é™¤è¿‘7å¤©å·²è´­ä¹°ç”¨æˆ·", "åªè¦å¥³æ€§å®¢æˆ·", "åªè¦VVIPç­‰çº§"],
  "kpi": "conversion_rate",
  "size_preference": {{"min": 100, "max": 500}},
  "is_clear": true,
  "summary": "æ‚¨å¸Œæœ›é’ˆå¯¹æ˜¥å­£æ–°å“æ‰‹è¢‹ä¸Šå¸‚ï¼Œåœˆé€‰25-44å²çš„å¥³æ€§VVIPå®¢æˆ·ï¼ˆæ’é™¤è¿‘æœŸå·²è´­ä¹°ç”¨æˆ·ï¼‰ï¼Œä»¥æå‡äº§å“è½¬åŒ–ç‡ã€‚"
}}
"""

    try:
        # ğŸ”¥ æ‰“å°å®Œæ•´çš„æç¤ºè¯
        logger.info("=" * 80)
        logger.info("ğŸ¤– LLM CALL - Intent Recognition Node")
        logger.info("=" * 80)
        logger.info(f"Multi-turn mode: {previous_intent is not None}")
        if previous_intent:
            logger.info(f"Previous intent: {json.dumps(previous_intent, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        logger.info("ğŸ“ PROMPT TO LLM:")
        logger.info(prompt)
        logger.info("-" * 80)

        # ç›´æ¥è°ƒç”¨LLMåº•å±‚æ–¹æ³•ï¼ˆä¸ä½¿ç”¨æ—§çš„ analyze_intentï¼‰
        logger.info(f"Calling LLM for intent recognition (multi-turn: {previous_intent is not None})")
        response_text = await llm.model.call(prompt)

        # ğŸ”¥ æ‰“å°LLMçš„å®Œæ•´å“åº”
        logger.info("-" * 80)
        logger.info("ğŸ“¥ LLM RESPONSE:")
        logger.info(response_text)
        logger.info("=" * 80)

        logger.info(f"Intent recognition raw response: {response_text[:200]}...")

        # å°è¯•è§£æJSON
        try:
            response = json.loads(response_text)
        except json.JSONDecodeError:
            # å¦‚æœæ— æ³•è§£æJSONï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            logger.warning("Failed to parse as JSON, trying to extract JSON block")
            # å°è¯•æå– {...} éƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                response = json.loads(json_match.group())
            else:
                raise ValueError("Cannot extract JSON from response")

        logger.info(f"Intent recognition parsed: {response}")

        # ğŸ”¥ å¦‚æœæ˜¯å¤šè½®å¯¹è¯ï¼Œè®°å½•èåˆæƒ…å†µ
        if previous_intent:
            logger.info("=" * 50)
            logger.info("Multi-turn Intent Merge Report:")
            logger.info(f"  Previous business_goal: {previous_intent.get('business_goal', 'N/A')}")
            logger.info(f"  New business_goal: {response.get('business_goal', 'N/A')}")
            logger.info(f"  Previous constraints: {previous_intent.get('constraints', [])}")
            logger.info(f"  New constraints: {response.get('constraints', [])}")
            logger.info(f"  Previous kpi: {previous_intent.get('kpi', 'N/A')}")
            logger.info(f"  New kpi: {response.get('kpi', 'N/A')}")
            logger.info("=" * 50)

        # è§£æç»“æœ
        is_clear = response.get("is_clear", True)  # é»˜è®¤ä¸ºTrueï¼Œåªæœ‰æ˜ç¡®æ ‡è®°falseæ‰è®¤ä¸ºä¸æ¸…æ¥š

        # æ„å»º UserIntent
        user_intent: UserIntent = {
            "business_goal": response.get("business_goal", ""),
            "target_audience": response.get("target_audience", {}),
            "constraints": response.get("constraints", []),
            "kpi": response.get("kpi", "conversion_rate"),
            "size_preference": response.get("size_preference", {"min": 50, "max": 500}),
        }

        # æå–è‡ªç„¶è¯­è¨€æ‘˜è¦
        summary = response.get("summary", "")
        if not summary:
            # å¦‚æœLLMæ²¡æœ‰è¿”å›summaryï¼Œç”Ÿæˆä¸€ä¸ªç®€å•çš„
            goal = user_intent.get("business_goal", "è¥é”€æ´»åŠ¨")
            summary = f"ç†è§£æ‚¨çš„éœ€æ±‚ï¼š{goal}"

        logger.info(f"Intent summary: {summary}")

        return {
            "user_intent": user_intent,
            "intent_status": "clear" if is_clear else "ambiguous",
            "intent_summary": summary,  # æ–°å¢ï¼šè‡ªç„¶è¯­è¨€æ‘˜è¦
        }

    except Exception as e:
        logger.error(f"Error in intent_recognition: {e}")
        # é»˜è®¤è¿”å›ä¸æ˜ç¡®çŠ¶æ€
        return {
            "user_intent": {
                "business_goal": "",
                "target_audience": {},
                "constraints": [],
                "kpi": "conversion_rate",
                "size_preference": {"min": 50, "max": 500},
            },
            "intent_status": "ambiguous",
        }


# =====================================================
# Node B: ask_clarification (æ¾„æ¸…/åé—®)
# =====================================================
async def ask_clarification_node(state: AgentState) -> dict[str, Any]:
    """
    Node B: æ¾„æ¸…/åé—®

    å½“æ„å›¾ä¸æ˜æ—¶ï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€å¼•å¯¼ç”¨æˆ·ç»§ç»­è¡¥å……ä¿¡æ¯ã€‚
    """
    logger.info("Executing ask_clarification_node")

    user_input = state.get("user_input", "")
    user_intent = state.get("user_intent", {})

    llm = get_llm_manager()

    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¥é”€ä¸“å®¶åŠ©æ‰‹ã€‚ç”¨æˆ·çš„æè¿°ä¸å¤Ÿæ¸…æ™°ï¼Œä½ éœ€è¦å¼•å¯¼ç”¨æˆ·è¡¥å……æ›´å¤šä¿¡æ¯ã€‚

ç”¨æˆ·è¾“å…¥ï¼š{user_input}
å½“å‰è¯†åˆ«çš„æ„å›¾ï¼š{json.dumps(user_intent, ensure_ascii=False)}

è¯·ç”Ÿæˆä¸€ä¸ªè‡ªç„¶è¯­è¨€çš„åé—®ï¼Œå¼•å¯¼ç”¨æˆ·è¡¥å……ä»¥ä¸‹ä¿¡æ¯ï¼š
1. ä¸šåŠ¡ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆå¦‚æå‡è½¬åŒ–ã€å¢åŠ è¥æ”¶ã€ä¿ƒè¿›åˆ°åº—ç­‰ï¼‰
2. æƒ³åœˆé€‰å“ªç±»äººç¾¤ï¼Ÿï¼ˆä¼šå‘˜ç­‰çº§ã€å¹´é¾„æ®µã€æ¶ˆè´¹åŠ›ç­‰ï¼‰
3. æœ‰ä»€ä¹ˆçº¦æŸæ¡ä»¶ï¼Ÿï¼ˆäººç¾¤è§„æ¨¡ã€é¢„ç®—ã€æ’é™¤æ¡ä»¶ç­‰ï¼‰

è¿”å›ä¸€æ®µè‡ªç„¶ã€å‹å¥½çš„å¼•å¯¼è¯­ï¼Œä¸è¦ç”ŸæˆJSONã€‚

ç¤ºä¾‹ï¼š
"æˆ‘ç†è§£æ‚¨æƒ³è¿›è¡Œäººç¾¤åœˆé€‰ã€‚ä¸ºäº†æ›´ç²¾å‡†åœ°å¸®æ‚¨ï¼Œèƒ½å¦å‘Šè¯‰æˆ‘ï¼šæ‚¨çš„æ ¸å¿ƒç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿæ¯”å¦‚æ˜¯æå‡è½¬åŒ–ç‡ã€å¢åŠ è¥æ”¶ï¼Œè¿˜æ˜¯ä¿ƒè¿›åˆ°åº—ï¼Ÿå¦å¤–ï¼Œæ‚¨å¸Œæœ›åœˆé€‰å“ªç±»å®¢æˆ·ï¼Ÿæ¯”å¦‚VIPå®¢æˆ·ã€å¹´è½»å®¢æˆ·ã€é«˜æ¶ˆè´¹å®¢æˆ·ç­‰ï¼Ÿ"
"""

    try:
        # ğŸ”¥ æ‰“å°å®Œæ•´çš„æç¤ºè¯
        logger.info("=" * 80)
        logger.info("ğŸ¤– LLM CALL - Ask Clarification Node")
        logger.info("=" * 80)
        logger.info("-" * 80)
        logger.info("ğŸ“ PROMPT TO LLM:")
        logger.info(prompt)
        logger.info("-" * 80)

        # ç›´æ¥è°ƒç”¨LLM
        response = await llm.model.call(prompt)
        clarification = response.strip()

        # ğŸ”¥ æ‰“å°LLMçš„å®Œæ•´å“åº”
        logger.info("-" * 80)
        logger.info("ğŸ“¥ LLM RESPONSE:")
        logger.info(response)
        logger.info("=" * 80)

        logger.info(f"Clarification question: {clarification}")

        return {
            "clarification_question": clarification,
            "final_response": clarification,  # ç›´æ¥è¿”å›ç»™ç”¨æˆ·
        }

    except Exception as e:
        logger.error(f"Error in ask_clarification: {e}")
        return {
            "clarification_question": "è¯·é—®æ‚¨æƒ³åœˆé€‰ä»€ä¹ˆæ ·çš„äººç¾¤ï¼Ÿèƒ½å¦æä¾›æ›´å¤šç»†èŠ‚ï¼Ÿ",
            "final_response": "è¯·é—®æ‚¨æƒ³åœˆé€‰ä»€ä¹ˆæ ·çš„äººç¾¤ï¼Ÿèƒ½å¦æä¾›æ›´å¤šç»†èŠ‚ï¼Ÿ",
        }


# =====================================================
# Node C: feature_matching (ç‰¹å¾åŒ¹é…)
# =====================================================
async def feature_matching_node(state: AgentState) -> dict[str, Any]:
    """
    Node C: ç‰¹å¾åŒ¹é…

    å°†ç”¨æˆ·æ„å›¾æ˜ å°„åˆ°å…·ä½“çš„æ•°æ®åº“ç‰¹å¾å­—æ®µã€‚
    """
    logger.info("Executing feature_matching_node")

    user_intent = state.get("user_intent", {})

    llm = get_llm_manager()

    # å‡†å¤‡ç‰¹å¾å…ƒæ•°æ®æ‘˜è¦
    feature_summary = {}
    for name, meta in FEATURE_METADATA.items():
        feature_summary[name] = {
            "display_name": meta["display_name"],
            "type": meta["type"],
            "description": meta["description"],
            "examples": meta["examples"][:2],  # åªå–å‰2ä¸ªç¤ºä¾‹
        }

    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚ç”¨æˆ·æƒ³è¿›è¡Œäººç¾¤åœˆé€‰ï¼Œä½ éœ€è¦å°†ç”¨æˆ·æ„å›¾æ˜ å°„åˆ°å…·ä½“çš„æ•°æ®åº“ç‰¹å¾å­—æ®µã€‚

ç”¨æˆ·æ„å›¾ï¼š
{json.dumps(user_intent, ensure_ascii=False, indent=2)}

å¯ç”¨çš„ç‰¹å¾å­—æ®µï¼š
{json.dumps(feature_summary, ensure_ascii=False, indent=2)}

è¯·åˆ†æç”¨æˆ·æ„å›¾ï¼ŒåŒ¹é…åˆé€‚çš„ç‰¹å¾å­—æ®µï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
  "matched_features": [
    {{
      "feature_name": "ç‰¹å¾åç§°",
      "operator": "æ“ä½œç¬¦ï¼ˆ>ã€>=ã€<ã€<=ã€==ã€inã€betweenï¼‰",
      "value": "ç‰¹å¾å€¼",
      "description": "è‡ªç„¶è¯­è¨€æè¿°"
    }}
  ],
  "is_success": true/false,  # æ˜¯å¦æˆåŠŸåŒ¹é…
  "reason": "å¦‚æœå¤±è´¥ï¼Œè¯´æ˜åŸå› "
}}

æ³¨æ„ï¼š
1. å¦‚æœç”¨æˆ·æ„å›¾ä¸­çš„æŸäº›æ¡ä»¶æ— æ³•ç”¨ç°æœ‰ç‰¹å¾è¡¨è¾¾ï¼Œè®¾ç½® is_success=false
2. å°½é‡åŒ¹é…å¤šä¸ªç‰¹å¾ï¼Œç»„åˆä½¿ç”¨ä»¥æ»¡è¶³ç”¨æˆ·éœ€æ±‚
3. å¯¹äºå¹´é¾„ã€ä¼šå‘˜ç­‰çº§ç­‰åˆ†ç±»ç‰¹å¾ï¼Œä½¿ç”¨ "in" æ“ä½œç¬¦
4. å¯¹äºæ¶ˆè´¹é¢ã€æ¬¡æ•°ç­‰æ•°å€¼ç‰¹å¾ï¼Œä½¿ç”¨ >ã€>=ã€< ç­‰æ“ä½œç¬¦

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

    try:
        # ğŸ”¥ æ‰“å°å®Œæ•´çš„æç¤ºè¯
        logger.info("=" * 80)
        logger.info("ğŸ¤– LLM CALL - Feature Matching Node")
        logger.info("=" * 80)
        logger.info("-" * 80)
        logger.info("ğŸ“ PROMPT TO LLM:")
        logger.info(prompt)
        logger.info("-" * 80)

        # ç›´æ¥è°ƒç”¨LLMè¿›è¡Œç‰¹å¾åŒ¹é…
        response_text = await llm.model.call(prompt)

        # ğŸ”¥ æ‰“å°LLMçš„å®Œæ•´å“åº”
        logger.info("-" * 80)
        logger.info("ğŸ“¥ LLM RESPONSE:")
        logger.info(response_text)
        logger.info("=" * 80)

        logger.info(f"Feature matching raw response: {response_text[:200]}...")

        # è§£æJSON
        try:
            response = json.loads(response_text)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONéƒ¨åˆ†
            logger.warning("Failed to parse as JSON, trying to extract JSON block")
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                response = json.loads(json_match.group())
            else:
                raise ValueError("Cannot extract JSON from response")

        logger.info(f"Feature matching result: {response}")

        is_success = response.get("is_success", True)  # é»˜è®¤æˆåŠŸ
        matched_features_raw = response.get("matched_features", [])

        # è½¬æ¢ä¸º MatchedFeature ç±»å‹
        matched_features: list[MatchedFeature] = []
        for feat in matched_features_raw:
            # è·å–ç‰¹å¾å…ƒæ•°æ®
            meta = FEATURE_METADATA.get(feat.get("feature_name"))
            if meta:
                matched_features.append({
                    "feature_name": feat.get("feature_name", ""),
                    "feature_type": meta["type"],
                    "operator": feat.get("operator", "=="),
                    "value": feat.get("value"),
                    "description": feat.get("description", ""),
                })

        # ç”Ÿæˆè‡ªç„¶è¯­è¨€æ‘˜è¦
        if matched_features:
            feature_list = "\n".join([f"â€¢ {f['description']}" for f in matched_features[:5]])
            summary = f"å·²ä¸ºæ‚¨åŒ¹é…{len(matched_features)}ä¸ªå…³é”®ç‰¹å¾ï¼š\n{feature_list}"
        else:
            summary = "æœªèƒ½æ‰¾åˆ°åŒ¹é…çš„ç‰¹å¾å­—æ®µï¼Œå»ºè®®è°ƒæ•´éœ€æ±‚æè¿°ã€‚"

        return {
            "matched_features": matched_features,
            "match_status": "success" if is_success else "needs_refinement",
            "feature_summary": summary,  # æ–°å¢ï¼šè‡ªç„¶è¯­è¨€æ‘˜è¦
        }

    except Exception as e:
        logger.error(f"Error in feature_matching: {e}")
        return {
            "matched_features": [],
            "match_status": "needs_refinement",
        }


# =====================================================
# Node D: request_modification (è¯·æ±‚ä¿®æ­£)
# =====================================================
async def request_modification_node(state: AgentState) -> dict[str, Any]:
    """
    Node D: è¯·æ±‚ä¿®æ­£

    å½“æ— æ³•æ‰¾åˆ°åŒ¹é…ç‰¹å¾æˆ–æ„å›¾ä¸å¯æ‰§è¡Œæ—¶ï¼Œå‘ŠçŸ¥ç”¨æˆ·åŸå› å¹¶å¼•å¯¼ä¿®æ”¹ã€‚
    """
    logger.info("Executing request_modification_node")

    user_intent = state.get("user_intent", {})
    matched_features = state.get("matched_features", [])

    llm = get_llm_manager()

    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¥é”€ä¸“å®¶åŠ©æ‰‹ã€‚ç”¨æˆ·çš„åœˆäººéœ€æ±‚æ— æ³•ç”¨ç°æœ‰çš„æ•°æ®ç‰¹å¾æ»¡è¶³ï¼Œä½ éœ€è¦å‘ŠçŸ¥åŸå› å¹¶å¼•å¯¼ä¿®æ”¹ã€‚

ç”¨æˆ·æ„å›¾ï¼š
{json.dumps(user_intent, ensure_ascii=False, indent=2)}

å·²åŒ¹é…çš„ç‰¹å¾ï¼š
{json.dumps(matched_features, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸€æ®µè‡ªç„¶ã€å‹å¥½çš„å¼•å¯¼è¯­ï¼Œè¯´æ˜ï¼š
1. å“ªäº›éœ€æ±‚æ— æ³•æ»¡è¶³ï¼Œä¸ºä»€ä¹ˆ
2. å»ºè®®ç”¨æˆ·å¦‚ä½•è°ƒæ•´éœ€æ±‚ï¼ˆç®€åŒ–æ¡ä»¶ã€æ¢ä¸ªè§’åº¦æè¿°ç­‰ï¼‰

è¿”å›çº¯æ–‡æœ¬ï¼Œä¸è¦JSONæ ¼å¼ã€‚

ç¤ºä¾‹ï¼š
"æŠ±æ­‰ï¼Œæ ¹æ®æ‚¨çš„æè¿°ï¼Œæˆ‘ä»¬æš‚æ—¶æ— æ³•åŒ¹é…åˆ°åˆé€‚çš„æ•°æ®ç‰¹å¾ã€‚å»ºè®®æ‚¨ï¼š1) ç®€åŒ–ä¸€äº›æ¡ä»¶ï¼Œæ¯”å¦‚å…ˆä¸é™åˆ¶åœ°åŸŸï¼›2) æˆ–è€…æ¢ä¸ªè§’åº¦ï¼Œæ¯”å¦‚å…³æ³¨ç”¨æˆ·çš„æ¶ˆè´¹è¡Œä¸ºè€Œä¸æ˜¯å…´è¶£æ ‡ç­¾ã€‚æ‚¨å¯ä»¥é‡æ–°æè¿°ä¸€ä¸‹éœ€æ±‚å—ï¼Ÿ"
"""

    try:
        # ğŸ”¥ æ‰“å°å®Œæ•´çš„æç¤ºè¯
        logger.info("=" * 80)
        logger.info("ğŸ¤– LLM CALL - Request Modification Node")
        logger.info("=" * 80)
        logger.info("-" * 80)
        logger.info("ğŸ“ PROMPT TO LLM:")
        logger.info(prompt)
        logger.info("-" * 80)

        # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆä¿®æ­£å»ºè®®
        response = await llm.model.call(prompt)
        modification_request = response.strip()

        # ğŸ”¥ æ‰“å°LLMçš„å®Œæ•´å“åº”
        logger.info("-" * 80)
        logger.info("ğŸ“¥ LLM RESPONSE:")
        logger.info(response)
        logger.info("=" * 80)

        logger.info(f"Modification request: {modification_request}")

        return {
            "modification_request": modification_request,
            "final_response": modification_request,  # ç›´æ¥è¿”å›ç»™ç”¨æˆ·
        }

    except Exception as e:
        logger.error(f"Error in request_modification: {e}")
        return {
            "modification_request": "æŠ±æ­‰ï¼Œæ— æ³•æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚è¯·é‡æ–°æè¿°æˆ–ç®€åŒ–æ¡ä»¶ã€‚",
            "final_response": "æŠ±æ­‰ï¼Œæ— æ³•æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚è¯·é‡æ–°æè¿°æˆ–ç®€åŒ–æ¡ä»¶ã€‚",
        }


# =====================================================
# Node E: strategy_generation (ç­–ç•¥ç”Ÿæˆ)
# =====================================================
async def strategy_generation_node(state: AgentState) -> dict[str, Any]:
    """
    Node E: ç­–ç•¥ç”Ÿæˆ

    ç”¨è‡ªç„¶è¯­è¨€è§£é‡Šå¦‚ä½•ç»„åˆè¿™äº›ç‰¹å¾æ¥æ»¡è¶³åœˆäººæ„å›¾ã€‚
    """
    logger.info("Executing strategy_generation_node")

    user_intent = state.get("user_intent", {})
    matched_features = state.get("matched_features", [])

    llm = get_llm_manager()

    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¥é”€ç­–ç•¥ä¸“å®¶ã€‚ç”¨æˆ·æƒ³è¿›è¡Œäººç¾¤åœˆé€‰ï¼Œä½ å·²ç»åŒ¹é…å¥½äº†ç‰¹å¾ï¼Œç°åœ¨éœ€è¦ç”Ÿæˆç­–ç•¥è§£é‡Šã€‚

ç”¨æˆ·æ„å›¾ï¼š
{json.dumps(user_intent, ensure_ascii=False, indent=2)}

åŒ¹é…çš„ç‰¹å¾ï¼š
{json.dumps(matched_features, ensure_ascii=False, indent=2)}

è¯·ç”¨è‡ªç„¶è¯­è¨€è§£é‡Šï¼š
1. æˆ‘ä»¬å°†å¦‚ä½•ç»„åˆè¿™äº›ç‰¹å¾æ¥åœˆé€‰äººç¾¤
2. è¿™ä¸ªç­–ç•¥ä¸ºä»€ä¹ˆèƒ½æ»¡è¶³ç”¨æˆ·çš„ä¸šåŠ¡ç›®æ ‡
3. é¢„æœŸèƒ½è¾¾åˆ°ä»€ä¹ˆæ•ˆæœ

è¿”å›ä¸€æ®µä¸“ä¸šã€æ¸…æ™°çš„ç­–ç•¥è¯´æ˜ï¼ˆ200-300å­—ï¼‰ï¼Œä¸è¦JSONæ ¼å¼ã€‚

ç¤ºä¾‹ï¼š
"æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨ä»¥ä¸‹åœˆé€‰ç­–ç•¥ï¼š

**ç›®æ ‡äººç¾¤å®šä½**ï¼šé”å®šVVIPå’ŒVIPå®¢æˆ·ï¼Œå¹´é¾„åœ¨25-44å²ä¹‹é—´ï¼Œè¿‘12ä¸ªæœˆæ¶ˆè´¹é¢è¶…è¿‡10ä¸‡å…ƒã€‚

**è¡Œä¸ºç­›é€‰**ï¼šä¼˜å…ˆé€‰æ‹©è¿‘30å¤©æµè§ˆæ‰‹è¢‹å“ç±»è¶…è¿‡10æ¬¡ã€ä¸”æœ‰åŠ è´­æœªä¸‹å•è®°å½•çš„é«˜æ„å‘ç”¨æˆ·ã€‚

**æ’é™¤æ¡ä»¶**ï¼šæ’é™¤è¿‘7å¤©å·²è´­ä¹°ç”¨æˆ·ï¼Œé¿å…è¥é”€ç–²åŠ³ã€‚

**é¢„æœŸæ•ˆæœ**ï¼šè¿™ä¸€ç­–ç•¥èƒ½å¤Ÿç²¾å‡†è§¦è¾¾é«˜ä»·å€¼ã€é«˜æ„å‘çš„æ½œåœ¨å®¢æˆ·ï¼Œé¢„è®¡è½¬åŒ–ç‡å¯æå‡30-50%ï¼ŒåŒæ—¶é¿å…å¯¹å·²è½¬åŒ–ç”¨æˆ·çš„é‡å¤æ‰“æ‰°ã€‚"
"""

    try:
        # ğŸ”¥ æ‰“å°å®Œæ•´çš„æç¤ºè¯
        logger.info("=" * 80)
        logger.info("ğŸ¤– LLM CALL - Strategy Generation Node")
        logger.info("=" * 80)
        logger.info("-" * 80)
        logger.info("ğŸ“ PROMPT TO LLM:")
        logger.info(prompt)
        logger.info("-" * 80)

        # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆç­–ç•¥è§£é‡Š
        response = await llm.model.call(prompt)
        strategy = response.strip()

        # ğŸ”¥ æ‰“å°LLMçš„å®Œæ•´å“åº”
        logger.info("-" * 80)
        logger.info("ğŸ“¥ LLM RESPONSE:")
        logger.info(response)
        logger.info("=" * 80)

        logger.info(f"Strategy explanation: {strategy[:100]}...")

        # æå–å‰200å­—ä½œä¸ºæ‘˜è¦
        strategy_summary = strategy[:200] + "..." if len(strategy) > 200 else strategy

        return {
            "strategy_explanation": strategy,
            "strategy_summary": strategy_summary,  # æ–°å¢ï¼šç­–ç•¥æ‘˜è¦
        }

    except Exception as e:
        logger.error(f"Error in strategy_generation: {e}")
        return {
            "strategy_explanation": "ç­–ç•¥ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
        }


# =====================================================
# Node F: impact_prediction (æ•ˆæœé¢„æµ‹/Toolè°ƒç”¨)
# =====================================================
async def impact_prediction_node(state: AgentState) -> dict[str, Any]:
    """
    Node F: æ•ˆæœé¢„æµ‹/Toolè°ƒç”¨

    è°ƒç”¨å·¥å…·èŠ‚ç‚¹è¿›è¡Œæ•°æ®æŸ¥è¯¢ã€æ•ˆæœé¢„æµ‹ã€‚
    ç›®å‰ä½¿ç”¨mockæ•°æ®æ¨¡æ‹ŸçœŸå®é¢„æµ‹ç»“æœã€‚
    """
    logger.info("Executing impact_prediction_node")

    matched_features = state.get("matched_features", [])
    user_intent = state.get("user_intent", {})

    # TODO: è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„æ•°æ®æŸ¥è¯¢å·¥å…·
    # ç›®å‰ä½¿ç”¨mockæ•°æ®æ¨¡æ‹Ÿ

    # ç®€å•æ¨¡æ‹Ÿï¼šæ ¹æ®åŒ¹é…çš„ç‰¹å¾ç­›é€‰ç”¨æˆ·
    filtered_users = MOCK_USERS_WITH_FEATURES.copy()

    # åº”ç”¨ç‰¹å¾è¿‡æ»¤ï¼ˆç®€åŒ–ç‰ˆï¼‰
    for feature in matched_features:
        name = feature["feature_name"]
        operator = feature["operator"]
        value = feature["value"]
        feature_type = feature.get("feature_type", "categorical")

        try:
            # æ ¹æ®ç‰¹å¾ç±»å‹è½¬æ¢ value çš„ç±»å‹
            if feature_type == "numeric":
                # æ•°å€¼ç±»å‹ - è½¬æ¢ä¸ºæ•°å­—
                if operator == "between":
                    # ç‰¹æ®Šå¤„ç† between æ“ä½œç¬¦
                    if isinstance(value, str):
                        # å°è¯•è§£æ "30 and 90" æˆ– "30-90" æˆ– "30,90" æ ¼å¼
                        import re
                        parts = re.split(r'\s+and\s+|\s*-\s*|\s*,\s*', value.strip())
                        if len(parts) == 2:
                            try:
                                min_val = float(parts[0]) if '.' in parts[0] else int(parts[0])
                                max_val = float(parts[1]) if '.' in parts[1] else int(parts[1])
                                value = [min_val, max_val]
                            except ValueError:
                                logger.warning(f"Cannot parse between value: {value}")
                                continue
                        else:
                            logger.warning(f"Invalid between value format: {value}")
                            continue
                    elif isinstance(value, (list, tuple)) and len(value) == 2:
                        min_val = float(value[0]) if isinstance(value[0], str) else value[0]
                        max_val = float(value[1]) if isinstance(value[1], str) else value[1]
                        value = [min_val, max_val]
                    else:
                        logger.warning(f"Invalid between value: {value}")
                        continue

                    # æ‰§è¡Œ between è¿‡æ»¤
                    filtered_users = [u for u in filtered_users if value[0] <= u.get(name, 0) <= value[1]]
                else:
                    # å…¶ä»–æ•°å€¼æ“ä½œç¬¦
                    if isinstance(value, str):
                        value = float(value) if '.' in value else int(value)

                    # æ•°å€¼æ¯”è¾ƒ
                    if operator == ">":
                        filtered_users = [u for u in filtered_users if u.get(name, 0) > value]
                    elif operator == ">=":
                        filtered_users = [u for u in filtered_users if u.get(name, 0) >= value]
                    elif operator == "<":
                        filtered_users = [u for u in filtered_users if u.get(name, 0) < value]
                    elif operator == "<=":
                        filtered_users = [u for u in filtered_users if u.get(name, 0) <= value]
                    elif operator == "==":
                        filtered_users = [u for u in filtered_users if u.get(name, 0) == value]

            elif feature_type == "categorical":
                # åˆ†ç±»ç±»å‹
                if operator == "==":
                    filtered_users = [u for u in filtered_users if u.get(name) == value]
                elif operator == "in":
                    # ç¡®ä¿ value æ˜¯åˆ—è¡¨
                    if not isinstance(value, (list, tuple)):
                        value = [value]
                    filtered_users = [u for u in filtered_users if u.get(name) in value]

            elif feature_type == "boolean":
                # å¸ƒå°”ç±»å‹
                if isinstance(value, str):
                    value = value.lower() in ['true', '1', 'yes']
                filtered_users = [u for u in filtered_users if u.get(name) == value]

        except (ValueError, TypeError) as e:
            logger.warning(f"Error filtering feature {name} with value {value}: {e}")
            # è·³è¿‡è¿™ä¸ªç‰¹å¾ï¼Œç»§ç»­å¤„ç†å…¶ä»–ç‰¹å¾
            continue

    # è®¡ç®—é¢„æµ‹æŒ‡æ ‡
    audience_size = len(filtered_users)

    # Mocké¢„æµ‹æ•°æ®
    if audience_size > 0:
        # åŸºäºäººç¾¤è§„æ¨¡å’Œè´¨é‡ä¼°ç®—è½¬åŒ–ç‡
        avg_loyalty = sum(u.get("brand_loyalty_score", 0) for u in filtered_users) / audience_size
        base_conversion_rate = 0.05  # åŸºç¡€è½¬åŒ–ç‡5%
        conversion_rate = base_conversion_rate * (1 + avg_loyalty / 100)  # æ ¹æ®å¿ è¯šåº¦è°ƒæ•´

        # ç»Ÿè®¡ä¼šå‘˜ç­‰çº§åˆ†å¸ƒ
        tier_distribution = {}
        for user in filtered_users:
            tier = user.get("tier", "Member")
            tier_distribution[tier] = tier_distribution.get(tier, 0) + 1

        # ä¼°ç®—æ”¶å…¥
        from app.data.mock_users import TIER_AVG_ORDER_VALUE
        estimated_revenue = 0
        for tier, count in tier_distribution.items():
            avg_order = TIER_AVG_ORDER_VALUE.get(tier, 18000)
            estimated_revenue += count * conversion_rate * avg_order

        # è®¡ç®—ROIï¼ˆå‡è®¾è¥é”€æˆæœ¬ä¸ºæ”¶å…¥çš„20%ï¼‰
        roi = estimated_revenue / (estimated_revenue * 0.2) if estimated_revenue > 0 else 0

        # äººç¾¤è´¨é‡åˆ†
        quality_score = avg_loyalty

        # Topç”¨æˆ·ï¼ˆå–å‰5ä¸ªï¼‰
        sorted_users = sorted(filtered_users, key=lambda u: u.get("score", 0), reverse=True)
        top_users = [
            {
                "name": u.get("name"),
                "tier": u.get("tier"),
                "score": u.get("score"),
                "r12m_spending": u.get("r12m_spending"),
            }
            for u in sorted_users[:5]
        ]

    else:
        # æ²¡æœ‰åŒ¹é…ç”¨æˆ·
        conversion_rate = 0
        estimated_revenue = 0
        roi = 0
        quality_score = 0
        tier_distribution = {}
        top_users = []

    prediction_result: PredictionResult = {
        "audience_size": audience_size,
        "conversion_rate": conversion_rate,
        "estimated_revenue": estimated_revenue,
        "roi": roi,
        "quality_score": quality_score,
        "tier_distribution": tier_distribution,
        "top_users": top_users,
    }

    logger.info(f"Prediction result: {prediction_result}")

    return {
        "prediction_result": prediction_result,
    }


# =====================================================
# Node G: final_analysis (ç»“æœè¾“å‡º)
# =====================================================
async def final_analysis_node(state: AgentState) -> dict[str, Any]:
    """
    Node G: ç»“æœè¾“å‡º

    å°†é¢„æµ‹æ•°æ®è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€çš„åˆ†ææŠ¥å‘Šã€‚
    åŒæ—¶è¾“å‡ºç»“æ„åŒ–çš„åœˆäººæ–¹æ¡ˆæ•°æ®ã€‚
    """
    logger.info("Executing final_analysis_node")

    prediction_result = state.get("prediction_result", {})
    strategy_explanation = state.get("strategy_explanation", "")
    user_intent = state.get("user_intent", {})
    matched_features = state.get("matched_features", [])

    llm = get_llm_manager()

    # æ„å»ºæç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚æ ¹æ®åœˆäººç­–ç•¥å’Œé¢„æµ‹ç»“æœï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„åˆ†ææŠ¥å‘Šã€‚

ç­–ç•¥è¯´æ˜ï¼š
{strategy_explanation}

é¢„æµ‹ç»“æœï¼š
{json.dumps(prediction_result, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ï¼š
1. **åœˆé€‰ç»“æœæ¦‚è§ˆ**ï¼ˆäººç¾¤è§„æ¨¡ã€ä¼šå‘˜åˆ†å¸ƒï¼‰
2. **æ ¸å¿ƒæŒ‡æ ‡é¢„æµ‹**ï¼ˆè½¬åŒ–ç‡ã€é¢„ä¼°æ”¶å…¥ã€ROIï¼‰
3. **Topç”¨æˆ·é¢„è§ˆ**ï¼ˆåˆ—å‡ºå‰3-5ä¸ªé«˜ä»·å€¼ç”¨æˆ·ï¼‰
4. **æ‰§è¡Œå»ºè®®**ï¼ˆåŸºäºæ•°æ®ç»™å‡ºçš„å»ºè®®ï¼‰

è¿”å›æ¸…æ™°ã€ä¸“ä¸šçš„markdownæ ¼å¼æŠ¥å‘Šï¼ˆ400-600å­—ï¼‰ã€‚
"""

    try:
        # ğŸ”¥ æ‰“å°å®Œæ•´çš„æç¤ºè¯
        logger.info("=" * 80)
        logger.info("ğŸ¤– LLM CALL - Final Analysis Node")
        logger.info("=" * 80)
        logger.info("-" * 80)
        logger.info("ğŸ“ PROMPT TO LLM:")
        logger.info(prompt)
        logger.info("-" * 80)

        # ç›´æ¥è°ƒç”¨LLMç”Ÿæˆåˆ†ææŠ¥å‘Š
        response = await llm.model.call(prompt)
        report = response.strip()

        # ğŸ”¥ æ‰“å°LLMçš„å®Œæ•´å“åº”
        logger.info("-" * 80)
        logger.info("ğŸ“¥ LLM RESPONSE:")
        logger.info(response)
        logger.info("=" * 80)

        logger.info(f"Final analysis report generated")

        # æ„å»ºç»“æ„åŒ–çš„åœˆäººæ–¹æ¡ˆ
        logger.info("Building segmentation proposal...")
        segmentation_proposal = _build_segmentation_proposal(
            user_intent,
            matched_features,
            prediction_result
        )
        logger.info(f"Segmentation proposal built: {segmentation_proposal is not None}")

        return {
            "final_response": report,
            "segmentation_proposal": segmentation_proposal,  # æ–°å¢ï¼šç»“æ„åŒ–æ–¹æ¡ˆ
        }

    except Exception as e:
        logger.error(f"Error in final_analysis: {e}")
        # ç”Ÿæˆç®€å•çš„åå¤‡æŠ¥å‘Š
        audience_size = prediction_result.get("audience_size", 0)
        conversion_rate = prediction_result.get("conversion_rate", 0)
        estimated_revenue = prediction_result.get("estimated_revenue", 0)
        roi = prediction_result.get("roi", 0)

        fallback_report = f"""# åœˆäººåˆ†ææŠ¥å‘Š

## åœˆé€‰ç»“æœæ¦‚è§ˆ
- **åœˆé€‰äººæ•°**: {audience_size}äºº
- **é¢„ä¼°è½¬åŒ–ç‡**: {conversion_rate:.2%}
- **é¢„ä¼°æ”¶å…¥**: Â¥{estimated_revenue:,.0f}
- **æŠ•èµ„å›æŠ¥ç‡(ROI)**: {roi:.2f}å€

## æ‰§è¡Œå»ºè®®
åŸºäºä»¥ä¸Šæ•°æ®ï¼Œå»ºè®®ç«‹å³æ‰§è¡Œè¥é”€æ´»åŠ¨ã€‚
"""

        # æ„å»ºç»“æ„åŒ–çš„åœˆäººæ–¹æ¡ˆï¼ˆå³ä½¿å‡ºé”™ä¹Ÿè¦è¿”å›ï¼‰
        try:
            segmentation_proposal = _build_segmentation_proposal(
                user_intent,
                matched_features,
                prediction_result
            )
        except Exception as e2:
            logger.error(f"Error building segmentation proposal: {e2}")
            segmentation_proposal = None

        return {
            "final_response": fallback_report,
            "segmentation_proposal": segmentation_proposal,
        }


def _build_segmentation_proposal(
    user_intent: dict[str, Any],
    matched_features: list[dict[str, Any]],
    prediction_result: dict[str, Any]
) -> dict[str, Any]:
    """
    æ„å»ºç»“æ„åŒ–çš„åœˆäººæ–¹æ¡ˆæ•°æ®
    """
    # æå–è¥é”€ç›®æ ‡
    business_goal = user_intent.get("business_goal", "æœªæŒ‡å®šè¥é”€ç›®æ ‡")

    # æå–çº¦æŸæ¡ä»¶
    constraints = user_intent.get("constraints", [])

    # æå–KPI
    kpi = user_intent.get("kpi", "conversion_rate")

    # æå–ç›®æ ‡äººç¾¤
    target_audience = user_intent.get("target_audience", {})

    # å°†åŒ¹é…çš„ç‰¹å¾è½¬æ¢ä¸º TargetTrait ç»“æ„
    trait_dict: dict[str, list[dict]] = {}
    for feature in matched_features:
        feature_name = feature.get("feature_name", "")
        feature_type = feature.get("feature_type", "categorical")
        operator = feature.get("operator", "=")
        value = feature.get("value", "")
        description = feature.get("description", "")

        # ç¡®å®šç‰¹å¾åˆ†ç±»
        category = _categorize_feature(feature_name, feature_type)

        if category not in trait_dict:
            trait_dict[category] = []

        trait_dict[category].append({
            "key": feature_name,
            "operator": operator,
            "value": value,
            "description": description
        })

    # æ„å»º target_traits
    target_traits = [
        {
            "category": category,
            "rules": rules
        }
        for category, rules in trait_dict.items()
    ]

    # æ„å»ºå®Œæ•´çš„æ–¹æ¡ˆ
    proposal = {
        "marketing_goal": business_goal,
        "constraints": constraints,
        "target_traits": target_traits,
        "kpi": kpi,
        "target_audience": target_audience
    }

    return proposal


def _categorize_feature(feature_name: str, feature_type: str) -> str:
    """
    æ ¹æ®ç‰¹å¾åç§°å’Œç±»å‹ï¼Œç¡®å®šç‰¹å¾åˆ†ç±»
    """
    # æ¶ˆè´¹ç›¸å…³
    if any(keyword in feature_name.lower() for keyword in ["amount", "value", "price", "æ¶ˆè´¹", "é‡‘é¢"]):
        return "æ¶ˆè´¹é—¨æ§›"

    # å“ç±»ç›¸å…³
    if any(keyword in feature_name.lower() for keyword in ["category", "å“ç±»", "ç±»åˆ«", "product"]):
        return "å“ç±»å…´è¶£"

    # è¡Œä¸ºç›¸å…³
    if any(keyword in feature_name.lower() for keyword in ["frequency", "visit", "è´­ä¹°", "è®¿é—®", "æ¬¡æ•°"]):
        return "è¡Œä¸ºä¹ æƒ¯"

    # æ—¶é—´ç›¸å…³
    if any(keyword in feature_name.lower() for keyword in ["recency", "æœ€è¿‘", "last", "æ—¶é—´"]):
        return "æ´»è·ƒåº¦"

    # ä¼šå‘˜ç­‰çº§
    if any(keyword in feature_name.lower() for keyword in ["tier", "level", "ç­‰çº§", "vip"]):
        return "ä¼šå‘˜ç­‰çº§"

    # é»˜è®¤åˆ†ç±»
    return "å…¶ä»–æ¡ä»¶"


# =====================================================
# èŠ‚ç‚¹æ³¨å†Œè¡¨
# =====================================================
AGENT_NODES = {
    "intent_recognition": intent_recognition_node,
    "ask_clarification": ask_clarification_node,
    "feature_matching": feature_matching_node,
    "request_modification": request_modification_node,
    "strategy_generation": strategy_generation_node,
    "impact_prediction": impact_prediction_node,
    "final_analysis": final_analysis_node,
}
