"""LangGraph nodes for the marketing agent."""
import logging
from typing import Any

from app.agent.state import AgentState, ThinkingStep
from app.models.llm import get_llm_manager
from app.data.selectors import select_audience
from app.data.mock_users import MOCK_USERS
from app.utils.metrics import get_calculator

logger = logging.getLogger(__name__)


async def intent_analysis_node(state: AgentState) -> dict[str, Any]:
    """
    Node 1: Analyze user intent and extract marketing goals.

    Parses the user's input to identify:
    - Primary KPI (conversion rate, revenue, etc.)
    - Target audience tiers
    - Behavioral criteria
    - Constraints and preferences

    Supports multi-turn conversations:
    - Uses conversation_context to understand history
    - Detects if user is modifying existing intent
    - Adjusts intent based on previous state
    """
    logger.info("Executing intent_analysis_node")

    # Update thinking steps
    thinking_steps = state.get("thinking_steps", [])
    thinking_steps = [
        {
            "id": "1",
            "title": "ä¸šåŠ¡æ„å›¾ä¸çº¦æŸè§£æ",
            "description": "æ­£åœ¨åˆ†æè¥é”€ç›®æ ‡å’Œæ ¸å¿ƒKPI...",
            "status": "active"
        }
    ]

    # Get LLM manager and analyze intent
    llm = get_llm_manager()
    user_input = state["user_input"]
    conversation_context = state.get("conversation_context", "")
    is_modification = state.get("is_modification", False)
    previous_intent = state.get("previous_intent")

    intent = None
    try:
        # Use context-aware prompt for multi-turn
        if conversation_context and is_modification and previous_intent:
            # User is modifying existing intent - use non-streaming for simplicity
            prompt_context = f"""ä½ æ˜¯ä¸€ä¸ªè¥é”€ä¸“å®¶ã€‚ç”¨æˆ·æ­£åœ¨ä¿®æ”¹ç°æœ‰çš„è¥é”€ç­–ç•¥ã€‚

{conversation_context}

è¯·åˆ†æç”¨æˆ·çš„æ–°è¾“å…¥ï¼Œå¹¶åŸºäºå½“å‰ç­–ç•¥è¿›è¡Œ**å¢é‡è°ƒæ•´**ã€‚è¿”å›è°ƒæ•´åçš„å®Œæ•´ç­–ç•¥ã€‚

ç”¨æˆ·çš„æ–°è¾“å…¥ï¼š{user_input}

è¯·è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- kpi: æ ¸å¿ƒKPIç›®æ ‡ (conversion_rate/revenue/visit_rate)
- target_tiers: ç›®æ ‡ä¼šå‘˜ç­‰çº§ (VVIP/VIP/Member)
- behavior_filters: è¡Œä¸ºç­›é€‰æ¡ä»¶
  - browse_frequency: æµè§ˆé¢‘æ¬¡é˜ˆå€¼ (0-100)
  - engagement_level: å‚ä¸åº¦çº§åˆ« (high/medium/low)
- size_preference: äººç¾¤è§„æ¨¡åå¥½
  - min: æœ€å°è§„æ¨¡
  - max: æœ€å¤§è§„æ¨¡
- constraints: é¢å¤–çº¦æŸæ¡ä»¶åˆ—è¡¨

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

            intent = await llm.analyze_intent(prompt_context)
            logger.info(f"Modified intent based on context: {intent}")

        else:
            # Fresh analysis - use streaming for faster first token
            logger.info("Using streaming LLM call for intent analysis")
            chunk_count = 0
            async for event in llm.analyze_intent_stream(user_input):
                if event["type"] == "chunk":
                    chunk_count += 1
                    if chunk_count == 1:
                        logger.info(f"âœ… First token received! Streaming in progress...")
                    # Log every 20 chunks to show progress
                    if chunk_count % 20 == 0:
                        logger.info(f"  Received {chunk_count} tokens...")
                elif event["type"] == "complete":
                    intent = event["data"]
                    logger.info(f"Extracted fresh intent (received {chunk_count} tokens total)")
                    logger.info(f"[DEBUG] Intent content: {intent}")  # Debug log
                    break
                elif event["type"] == "error":
                    raise Exception(event["data"])

    except Exception as e:
        logger.error(f"Error analyzing intent: {e}")
        intent = None

    # Fallback to default or previous intent if needed
    if intent is None:
        if previous_intent:
            intent = previous_intent
        else:
            intent = {
                "kpi": "conversion_rate",
                "target_tiers": ["VVIP", "VIP"],
                "behavior_filters": {},
                "size_preference": {"min": 50, "max": 500},
                "constraints": []
            }

    # Mark step as completed with detailed description
    kpi = intent.get('kpi', 'N/A')
    target_tiers = intent.get('target_tiers', [])
    behavior_filters = intent.get('behavior_filters', {})
    size_pref = intent.get('size_preference', {})
    constraints = intent.get('constraints', [])

    # Build detailed natural language description
    description_parts = []

    # KPIç›®æ ‡
    kpi_map = {
        'conversion_rate': 'è½¬åŒ–ç‡ï¼ˆCVRï¼‰',
        'revenue': 'è¥æ”¶å¢é•¿',
        'visit_rate': 'åˆ°åº—ç‡',
        'engagement': 'äº’åŠ¨å‚ä¸åº¦'
    }
    description_parts.append(f"**æ ¸å¿ƒKPIç›®æ ‡**: {kpi_map.get(kpi, kpi)}")

    # ç›®æ ‡äººç¾¤ç­‰çº§
    if target_tiers:
        # Filter out None values
        target_tiers_filtered = [t for t in target_tiers if t is not None]
        if target_tiers_filtered:
            tier_desc = "ã€".join(target_tiers_filtered)
            description_parts.append(f"**ç›®æ ‡å®¢æˆ·ç­‰çº§**: {tier_desc}")

    # è¡Œä¸ºç­›é€‰æ¡ä»¶
    if behavior_filters:
        behavior_desc = []
        browse_freq = behavior_filters.get('browse_frequency')
        if browse_freq is not None:
            behavior_desc.append(f"æµè§ˆé¢‘æ¬¡â‰¥{browse_freq}")

        engagement = behavior_filters.get('engagement_level')
        if engagement is not None:
            level_map = {'high': 'é«˜', 'medium': 'ä¸­', 'low': 'ä½'}
            level_val = level_map.get(engagement, engagement)
            behavior_desc.append(f"å‚ä¸åº¦{level_val}")

        # Filter out None values before joining
        behavior_desc = [b for b in behavior_desc if b is not None]
        if behavior_desc:
            description_parts.append(f"**è¡Œä¸ºè¦æ±‚**: {', '.join(behavior_desc)}")

    # äººç¾¤è§„æ¨¡åå¥½
    if size_pref:
        min_size = size_pref.get('min', 0)
        max_size = size_pref.get('max', 0)
        if min_size or max_size:
            description_parts.append(f"**äººç¾¤è§„æ¨¡**: {min_size}-{max_size}äºº")

    # é¢å¤–çº¦æŸ
    if constraints:
        # Filter out None values
        constraints_filtered = [c for c in constraints if c is not None]
        if constraints_filtered:
            description_parts.append(f"**çº¦æŸæ¡ä»¶**: {', '.join(constraints_filtered)}")

    # æ˜¯å¦æ˜¯ä¿®æ”¹æ„å›¾
    if is_modification:
        description_parts.insert(0, "ğŸ”„ **æ£€æµ‹åˆ°æ„å›¾ä¿®æ”¹** - åŸºäºä¸Šä¸€è½®ç»“æœè¿›è¡Œå¢é‡è°ƒæ•´")

    thinking_steps[0]["description"] = "\n".join(description_parts)
    thinking_steps[0]["status"] = "completed"

    return {
        "intent": intent,
        "thinking_steps": thinking_steps
    }


async def feature_extraction_node(state: AgentState) -> dict[str, Any]:
    """
    Node 2: Extract multi-dimensional features for audience segmentation.

    Based on the identified intent, generates:
    - Filtering rules for different user dimensions
    - Feature weights and importance
    - Business logic explanations
    """
    logger.info("Executing feature_extraction_node")

    thinking_steps = state.get("thinking_steps", [])
    intent = state.get("intent", {})

    # Add second thinking step
    thinking_steps.append({
        "id": "2",
        "title": "å¤šç»´ç‰¹å¾æ‰«æ",
        "description": "æ­£åœ¨æå–äººç¾¤çš„æ¶ˆè´¹åŠ›ã€å…´è¶£ã€æ´»è·ƒåº¦ç­‰ç‰¹å¾...",
        "status": "active"
    })

    llm = get_llm_manager()

    features = None
    try:
        # Use streaming for faster first token
        logger.info("Using streaming LLM call for feature extraction")
        chunk_count = 0
        async for event in llm.extract_features_stream(intent):
            if event["type"] == "chunk":
                chunk_count += 1
                if chunk_count == 1:
                    logger.info(f"âœ… First token received! Streaming in progress...")
                if chunk_count % 20 == 0:
                    logger.info(f"  Received {chunk_count} tokens...")
            elif event["type"] == "complete":
                features = event["data"]
                logger.info(f"Extracted features (received {chunk_count} tokens total)")
                break
            elif event["type"] == "error":
                raise Exception(event["data"])
    except Exception as e:
        logger.error(f"Error extracting features: {e}")
        features = None

    # Fallback if needed
    if features is None:
        features = {
            "feature_rules": [],
            "weights": {},
            "explanation": "åŸºäºä¼šå‘˜ç­‰çº§å’Œè¡Œä¸ºç‰¹å¾çš„å¤šç»´ç­›é€‰"
        }

    # Build detailed natural language description
    description_parts = []

    # ç‰¹å¾ç»´åº¦è¯´æ˜
    target_tiers = intent.get('target_tiers', [])
    if target_tiers:
        # Filter out None values
        target_tiers_filtered = [t for t in target_tiers if t is not None]
        if target_tiers_filtered:
            description_parts.append(f"**ä¼šå‘˜ç­‰çº§ç­›é€‰**: å®šä½{', '.join(target_tiers_filtered)}å®¢æˆ·ç¾¤ä½“")

    # è¡Œä¸ºç‰¹å¾
    behavior_filters = intent.get('behavior_filters', {})
    if behavior_filters:
        behavior_features = []
        browse_freq = behavior_filters.get('browse_frequency')
        if browse_freq is not None:
            behavior_features.append(f"é«˜é¢‘æµè§ˆç”¨æˆ·ï¼ˆé˜ˆå€¼{browse_freq}ï¼‰")

        engagement = behavior_filters.get('engagement_level')
        if engagement is not None:
            level_desc = {'high': 'é«˜åº¦æ´»è·ƒ', 'medium': 'ä¸­åº¦æ´»è·ƒ', 'low': 'ä½æ´»è·ƒåº¦'}
            desc = level_desc.get(engagement, f'{engagement}æ´»è·ƒåº¦')
            behavior_features.append(desc)

        # Filter out None values before joining
        behavior_features = [f for f in behavior_features if f is not None]
        if behavior_features:
            description_parts.append(f"**è¡Œä¸ºç‰¹å¾**: {', '.join(behavior_features)}")

    # æ¶ˆè´¹åŠ›åˆ†æ
    kpi = intent.get('kpi', '')
    if kpi == 'revenue':
        description_parts.append("**æ¶ˆè´¹åŠ›**: ä¼˜å…ˆåœˆé€‰é«˜å®¢å•ä»·ã€å¤è´­ç‡é«˜çš„ç”¨æˆ·")
    elif kpi == 'conversion_rate':
        description_parts.append("**è½¬åŒ–å€¾å‘**: ä¼˜å…ˆåœˆé€‰é«˜æ„å‘ã€æµè§ˆæ·±åº¦é«˜çš„ç”¨æˆ·")
    elif kpi == 'visit_rate':
        description_parts.append("**åˆ°åº—æ„æ„¿**: ä¼˜å…ˆåœˆé€‰è¿‘æœŸæ´»è·ƒã€åœ°ç†ä½ç½®åŒ¹é…çš„ç”¨æˆ·")

    # ç‰¹å¾æƒé‡è¯´æ˜
    weights = features.get('weights', {})
    if weights:
        weight_items = []
        for key, val in weights.items():
            if key is not None and val is not None:
                weight_items.append(f"{key}({val})")
        if weight_items:
            description_parts.append(f"**ç‰¹å¾æƒé‡**: {', '.join(weight_items)}")

    # LLMç”Ÿæˆçš„è¯´æ˜
    explanation = features.get('explanation', '')
    if explanation:
        description_parts.append(f"**ç­–ç•¥è¯´æ˜**: {explanation}")

    # Mark step as completed
    thinking_steps[-1]["description"] = "\n".join(description_parts) if description_parts else "å·²å®Œæˆå¤šç»´ç‰¹å¾æå–"
    thinking_steps[-1]["status"] = "completed"

    return {
        "features": features,
        "thinking_steps": thinking_steps
    }


async def audience_selection_node(state: AgentState) -> dict[str, Any]:
    """
    Node 3: Select audience based on intent and features.

    Applies filtering rules to the user pool:
    - Filters by membership tier
    - Applies behavior criteria
    - Calculates match scores
    - Returns ranked audience list
    """
    logger.info("Executing audience_selection_node")

    thinking_steps = state.get("thinking_steps", [])
    intent = state.get("intent", {})

    # Add third thinking step
    thinking_steps.append({
        "id": "3",
        "title": "äººç¾¤ç­–ç•¥ç»„åˆè®¡ç®—",
        "description": "æ­£åœ¨åº”ç”¨ç­›é€‰è§„åˆ™å¹¶è®¡ç®—äººç¾¤ç­–ç•¥...",
        "status": "active"
    })

    try:
        # Select audience based on intent
        selected_users, metadata = select_audience(intent, MOCK_USERS)
        logger.info(f"Selected {len(selected_users)} users. Metadata: {metadata}")
    except Exception as e:
        logger.error(f"Error selecting audience: {e}")
        selected_users = []
        metadata = {}

    # Build detailed natural language description
    description_parts = []

    # åœˆé€‰ç»“æœæ¦‚è§ˆ
    total_selected = len(selected_users)
    description_parts.append(f"âœ… **åœˆé€‰å®Œæˆ**: ä»å…¨é‡ç”¨æˆ·ä¸­ç­›é€‰å‡º **{total_selected}äºº** é«˜æ½œäººç¾¤")

    # ä¼šå‘˜ç­‰çº§åˆ†å¸ƒ
    tier_distribution = {}
    for user in selected_users:
        tier = user.get("tier", "Member")
        tier_distribution[tier] = tier_distribution.get(tier, 0) + 1

    if tier_distribution:
        tier_desc = []
        tier_order = ["VVIP", "VIP", "Member"]
        for tier in tier_order:
            if tier in tier_distribution:
                count = tier_distribution[tier]
                percentage = (count / total_selected * 100) if total_selected > 0 else 0
                tier_desc.append(f"{tier} {count}äºº({percentage:.0f}%)")
        if tier_desc:
            description_parts.append(f"**ä¼šå‘˜åˆ†å¸ƒ**: {' | '.join(tier_desc)}")

    # å¹³å‡åŒ¹é…åº¦
    if selected_users:
        avg_match_score = sum(u.get("matchScore", 0) for u in selected_users) / len(selected_users)
        description_parts.append(f"**å¹³å‡åŒ¹é…åº¦**: {avg_match_score:.1f}åˆ†")

    # Top 3ç”¨æˆ·é¢„è§ˆ
    if selected_users:
        top_3 = selected_users[:3]
        top_users_desc = []
        for i, user in enumerate(top_3, 1):
            name = user.get("name", "æœªçŸ¥")
            tier = user.get("tier", "Member")
            score = user.get("score", 0)
            match_score = user.get("matchScore", 0)
            top_users_desc.append(f"{i}. {name}({tier}, åŸºç¡€{score}åˆ†, åŒ¹é…{match_score:.1f}åˆ†)")

        description_parts.append(f"**Top 3ç”¨æˆ·**:\n" + "\n".join(top_users_desc))

    # ç­›é€‰ç­–ç•¥è¯´æ˜
    target_tiers = intent.get('target_tiers', [])
    if target_tiers:
        # Filter out None values
        target_tiers_filtered = [t for t in target_tiers if t is not None]
        if target_tiers_filtered:
            description_parts.append(f"**ç­›é€‰ç­–ç•¥**: å®šä½{'/'.join(target_tiers_filtered)}ç­‰çº§ï¼ŒåŒ¹é…åº¦åŠ æƒæ’åº")

    # æ•°æ®è´¨é‡è¯„ä¼°
    if total_selected > 0:
        if total_selected < 10:
            description_parts.append("âš ï¸ **å»ºè®®**: å½“å‰äººç¾¤è§„æ¨¡è¾ƒå°ï¼Œå¯è€ƒè™‘æ”¾å®½ç­›é€‰æ¡ä»¶æ‰©å¤§è¦†ç›–")
        elif total_selected > 200:
            description_parts.append("ğŸ’¡ **å»ºè®®**: äººç¾¤è§„æ¨¡è¾ƒå¤§ï¼Œå¯è¿›ä¸€æ­¥æå‡ç­›é€‰ç²¾å‡†åº¦")
        else:
            description_parts.append("âœ¨ **è¯„ä¼°**: äººç¾¤è§„æ¨¡åˆç†ï¼ŒåŒ¹é…åº¦è‰¯å¥½")

    # Mark step as completed
    thinking_steps[-1]["description"] = "\n".join(description_parts) if description_parts else f"å·²åœˆé€‰{total_selected}äºº"
    thinking_steps[-1]["status"] = "completed"

    return {
        "audience": selected_users,
        "thinking_steps": thinking_steps
    }


async def prediction_optimization_node(state: AgentState) -> dict[str, Any]:
    """
    Node 4: Predict campaign performance and optimize.

    Calculates key metrics:
    - Conversion rate based on audience size and quality
    - Estimated revenue
    - ROI
    - Audience quality score
    """
    logger.info("Executing prediction_optimization_node")

    thinking_steps = state.get("thinking_steps", [])
    audience = state.get("audience", [])

    # Add fourth thinking step
    thinking_steps.append({
        "id": "4",
        "title": "æ•ˆæœé¢„æµ‹ä¸ä¼˜åŒ–",
        "description": "æ­£åœ¨è®¡ç®—è½¬åŒ–ç‡ã€ROIç­‰æ ¸å¿ƒæŒ‡æ ‡...",
        "status": "active"
    })

    # Calculate metrics
    calculator = get_calculator()
    audience_size = len(audience)
    avg_score = sum(u.get("matchScore", 0) for u in audience) / audience_size if audience else 0

    # Count tier distribution
    tier_distribution = {"VVIP": 0, "VIP": 0, "Member": 0}
    for user in audience:
        tier = user.get("tier", "Member")
        if tier in tier_distribution:
            tier_distribution[tier] += 1

    try:
        metrics = calculator.estimate_metrics(
            audience_size=audience_size,
            avg_user_score=avg_score,
            audience_tier_distribution=tier_distribution
        )
        logger.info(f"Calculated metrics: {metrics}")
    except Exception as e:
        logger.error(f"Error calculating metrics: {e}")
        metrics = {
            "audience_size": audience_size,
            "conversion_rate": 0,
            "estimated_revenue": 0,
            "roi": 0,
            "reach_rate": 0,
            "quality_score": 0
        }

    # Build detailed natural language description
    description_parts = []

    # æ ¸å¿ƒæŒ‡æ ‡é¢„æµ‹
    description_parts.append("ğŸ“Š **æ ¸å¿ƒæŒ‡æ ‡é¢„æµ‹**")

    # è½¬åŒ–ç‡
    conversion_rate = metrics.get("conversion_rate", 0)
    description_parts.append(f"â€¢ **é¢„ä¼°è½¬åŒ–ç‡**: {conversion_rate:.2%}")
    if conversion_rate > 0.10:
        description_parts.append("  âœ¨ è½¬åŒ–ç‡è¡¨ç°ä¼˜ç§€")
    elif conversion_rate > 0.05:
        description_parts.append("  âœ“ è½¬åŒ–ç‡è¡¨ç°è‰¯å¥½")
    else:
        description_parts.append("  âš ï¸ è½¬åŒ–ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–äººç¾¤è´¨é‡")

    # é¢„ä¼°æ”¶å…¥
    estimated_revenue = metrics.get("estimated_revenue", 0)
    description_parts.append(f"â€¢ **é¢„ä¼°æ”¶å…¥**: Â¥{estimated_revenue:,.0f}")

    # ROI
    roi = metrics.get("roi", 0)
    description_parts.append(f"â€¢ **æŠ•èµ„å›æŠ¥ç‡(ROI)**: {roi:.2f}å€")
    if roi > 5:
        description_parts.append("  ğŸ¯ ROIè¡¨ç°ä¼˜å¼‚ï¼Œå»ºè®®ç«‹å³æ‰§è¡Œ")
    elif roi > 3:
        description_parts.append("  âœ“ ROIè¾¾æ ‡ï¼Œå¯ä»¥æ‰§è¡Œ")
    else:
        description_parts.append("  âš ï¸ ROIåä½ï¼Œå»ºè®®ä¼˜åŒ–ç­–ç•¥")

    # è§¦è¾¾ç‡
    reach_rate = metrics.get("reach_rate", 0)
    description_parts.append(f"â€¢ **è§¦è¾¾ç‡**: {reach_rate:.1f}%")

    # äººç¾¤è´¨é‡åˆ†
    quality_score = metrics.get("quality_score", 0)
    description_parts.append(f"â€¢ **äººç¾¤è´¨é‡åˆ†**: {quality_score:.1f}åˆ†")

    # äººç¾¤è§„æ¨¡åˆ†æ
    description_parts.append(f"\nğŸ“ˆ **äººç¾¤è§„æ¨¡åˆ†æ**")
    description_parts.append(f"â€¢ ç›®æ ‡äººç¾¤: {audience_size}äºº")

    # å„ç­‰çº§é¢„ä¼°æ”¶å…¥
    if tier_distribution:
        from app.data.mock_users import TIER_AVG_ORDER_VALUE
        tier_revenue_parts = []
        for tier in ["VVIP", "VIP", "Member"]:
            count = tier_distribution.get(tier, 0)
            if count > 0:
                avg_order = TIER_AVG_ORDER_VALUE.get(tier, 18000)
                tier_revenue = count * conversion_rate * avg_order
                tier_revenue_parts.append(f"  â€¢ {tier}: {count}äºº Ã— {conversion_rate:.1%} Ã— Â¥{avg_order:,} = Â¥{tier_revenue:,.0f}")

        if tier_revenue_parts:
            description_parts.append("â€¢ åˆ†å±‚æ”¶å…¥è´¡çŒ®:")
            description_parts.extend(tier_revenue_parts)

    # ä¼˜åŒ–å»ºè®®
    description_parts.append(f"\nğŸ’¡ **ä¼˜åŒ–å»ºè®®**")

    if audience_size < 50:
        description_parts.append("â€¢ äººç¾¤è§„æ¨¡åå°ï¼Œå»ºè®®é€‚å½“æ”¾å®½ç­›é€‰æ¡ä»¶")

    if avg_score < 80:
        description_parts.append("â€¢ å¹³å‡åŒ¹é…åº¦åä½ï¼Œå»ºè®®æå‡ç‰¹å¾æƒé‡")

    if tier_distribution.get("VVIP", 0) / audience_size > 0.7 if audience_size > 0 else False:
        description_parts.append("â€¢ VVIPå æ¯”é«˜ï¼Œå»ºè®®å¢åŠ ä¸ªæ€§åŒ–æœåŠ¡è§¦ç‚¹")

    if conversion_rate < 0.05:
        description_parts.append("â€¢ è½¬åŒ–ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–è¥é”€æ–‡æ¡ˆå’Œè§¦è¾¾æ¸ é“")

    # Mark step as completed
    thinking_steps[-1]["description"] = "\n".join(description_parts)
    thinking_steps[-1]["status"] = "completed"

    return {
        "metrics": metrics,
        "thinking_steps": thinking_steps
    }


async def response_generation_node(state: AgentState) -> dict[str, Any]:
    """
    Node 5: Generate natural language response.

    Creates a human-readable summary of:
    - Selected audience insights
    - Key metrics and KPIs
    - Strategic recommendations
    """
    logger.info("Executing response_generation_node")

    thinking_steps = state.get("thinking_steps", [])
    audience = state.get("audience", [])
    metrics = state.get("metrics", {})
    intent = state.get("intent", {})

    # Add fifth thinking step
    thinking_steps.append({
        "id": "5",
        "title": "ç­–ç•¥æ€»ç»“ä¸å»ºè®®",
        "description": "æ­£åœ¨ç”Ÿæˆè¥é”€ç­–ç•¥æ€»ç»“...",
        "status": "active"
    })

    # Prepare analysis summary
    analysis_summary = {
        "audience_size": len(audience),
        "avg_score": sum(u.get("matchScore", 0) for u in audience) / len(audience) if audience else 0,
        "conversion_rate": metrics.get("conversion_rate", 0),
        "estimated_revenue": metrics.get("estimated_revenue", 0),
        "roi": metrics.get("roi", 0),
        "reach_rate": metrics.get("reach_rate", 0),
        "quality_score": metrics.get("quality_score", 0),
        "kpi": intent.get("kpi", "")
    }

    llm = get_llm_manager()

    response = None
    try:
        # Use streaming for faster first token
        logger.info("Using streaming LLM call for response generation")
        chunk_count = 0
        async for event in llm.generate_response_stream(analysis_summary):
            if event["type"] == "chunk":
                chunk_count += 1
                if chunk_count == 1:
                    logger.info(f"âœ… First token received! Streaming in progress...")
                if chunk_count % 20 == 0:
                    logger.info(f"  Received {chunk_count} tokens...")
            elif event["type"] == "complete":
                response = event["data"]
                logger.info(f"Generated response (received {chunk_count} tokens total)")
                break
            elif event["type"] == "error":
                raise Exception(event["data"])
    except Exception as e:
        logger.error(f"Error generating response: {e}")
        response = None

    # Fallback if needed
    if response is None:
        response = f"å·²ä¸ºæ‚¨åœˆé€‰{len(audience)}äººé«˜æ½œäººç¾¤ã€‚é¢„ä¼°è½¬åŒ–ç‡{metrics.get('conversion_rate', 0):.1%}ï¼Œé¢„ä¼°æ”¶å…¥Â¥{metrics.get('estimated_revenue', 0):,.0f}ã€‚"

    # Update thinking step with summary
    thinking_steps[-1]["description"] = f"âœ… åˆ†æå®Œæˆ\n\n{response}"
    thinking_steps[-1]["status"] = "completed"

    return {
        "final_response": response,
        "thinking_steps": thinking_steps
    }


# Node registry for easy access
AGENT_NODES = {
    "intent_analysis": intent_analysis_node,
    "feature_extraction": feature_extraction_node,
    "audience_selection": audience_selection_node,
    "prediction_optimization": prediction_optimization_node,
    "response_generation": response_generation_node,
}
